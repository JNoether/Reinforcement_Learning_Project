{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch \n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from MDP import MDP\n",
    "\n",
    "import stable_baselines3\n",
    "import sb3_contrib\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Neural Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    input : 2 X 4 X 4 grid\n",
    "    label : Move [0;6]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # first layer: input\n",
    "        self.conv1 = nn.Conv2d(2, 8, 2)\n",
    "\n",
    "        #second layer : 2nd convolution\n",
    "        self.conv2 = nn.Conv2d(8, 16, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 32)\n",
    "\n",
    "        self.out = nn.Linear(32, 6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = self.out(x)\n",
    "    \n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(2, 8, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (out): Linear(in_features=32, out_features=6, bias=True)\n",
      ")\n",
      "number of parameters: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating model\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "print(f\"number of parameters: {len(params)}\")\n",
    "\n",
    "#loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"Net\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom environment\n",
    "from gym import spaces\n",
    "\n",
    "class Gridworld(gym.Env):\n",
    "\n",
    "    metadata = {\"render.modes\" : [\"human\"]}\n",
    "\n",
    "    def __init__(self, dir = [\"data\", \"data_easy\", \"data_medium\"], type = [\"train\"], lambda1 = 0.01, lambda2 = 0.1, lambda3 = 1, load_optimal = False) -> None:\n",
    "        super(Gridworld, self).__init__()\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(low = 0, high = 10, shape = (2, 4, 4))\n",
    "\n",
    "        #available MDPs\n",
    "        self.dir = dir\n",
    "        self.type = type\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.lambda3 = lambda3\n",
    "\n",
    "        self.actions = [\"move\", \"turnLeft\", \"turnRight\", \"pickMarker\", \"putMarker\",\"finish\"]\n",
    "        self.actionsDict = {\"move\" : 0, \"turnLeft\" : 1, \"turnRight\" : 2, \"pickMarker\" : 3, \"putMarker\" : 4, \"finish\" : 5}\n",
    "\n",
    "        self.load_optimal = load_optimal\n",
    "\n",
    "    def reset(self):\n",
    "        nextDir, nextType = np.random.choice(self.dir), np.random.choice(self.type)\n",
    "        self.nexti = np.random.choice(os.listdir(os.sep.join([\"datasets\", nextDir, nextType, \"task\"])))\n",
    "        self.nexti = re.sub(r\"\\D\", \"\", self.nexti)\n",
    "        self.currentMDP = MDP(nextDir, nextType, self.nexti, lambda1= self.lambda1, lambda2 = self.lambda2, lambda3 =self.lambda3)\n",
    "\n",
    "        # load optimal sequence if possible\n",
    "        if self.load_optimal:\n",
    "            try:\n",
    "                with open(os.sep.join([\"datasets\", nextDir, nextType, \"seq\", self.nexti + \"_seq.json\"])) as grid:\n",
    "                    grid = json.load(grid)\n",
    "                    self.optimal_seq = grid[\"sequence\"]\n",
    "                    # current step\n",
    "                    assert self.optimal_seq[-1] == \"finish\"\n",
    "            except:\n",
    "                self.optimal_seq = []\n",
    "        self.steps = 0\n",
    "        return self.currentMDP.get_current_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        nextState, rew, done, info = self.currentMDP.sample_next_state_and_reward(self.actions[action])\n",
    "        self.steps += 1\n",
    "        if self.steps > 500:\n",
    "            return nextState, -1, True, info \n",
    "\n",
    "        return nextState, rew -0.025, done, info \n",
    "        \n",
    "    def render(self):\n",
    "        self.currentMDP.print_grid()\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def action_masks(self):\n",
    "        # force agent to take optimal action if possible\n",
    "        if self.load_optimal and self.optimal_seq:\n",
    "            mask = np.zeros(6)\n",
    "            mask[self.actionsDict[self.optimal_seq[self.steps]]] = 1\n",
    "            return mask\n",
    "\n",
    "\n",
    "        mat = self.currentMDP.get_current_state()\n",
    "        if np.array_equal(mat[0], mat[1]):\n",
    "            return np.array([0,0,0,0,0,1])\n",
    "        \n",
    "        return self.currentMDP.action_mask()\n",
    "\n",
    "    # functions bellow are only used for inheritance \n",
    "    def get_MDP(self):\n",
    "        return self.currentMDP\n",
    "\n",
    "    def get_MDP_name(self):\n",
    "        return self.nextDir, self.nextType, self.nexti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnv = Gridworld(dir = [\"data\"], load_optimal= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' '.' '#' '.']\n",
      "  ['.' '.' '#' '#']\n",
      "  ['O' '.' '#' '#']\n",
      "  ['>' '.' '#' '#']]\n",
      "\n",
      " [['#' '.' '#' '.']\n",
      "  ['.' '.' '#' '#']\n",
      "  ['O' '.' '#' '#']\n",
      "  ['.' '>' '#' '#']]]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[[['#' '.' '#' '.']\n",
      "  ['.' '.' '#' '#']\n",
      "  ['O' '.' '#' '#']\n",
      "  ['.' '>' '#' '#']]\n",
      "\n",
      " [['#' '.' '#' '.']\n",
      "  ['.' '.' '#' '#']\n",
      "  ['O' '.' '#' '#']\n",
      "  ['.' '>' '#' '#']]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testEnv.reset()\n",
    "testEnv.render()\n",
    "print(testEnv.action_masks())\n",
    "testEnv.step(np.argmax(testEnv.action_masks()))\n",
    "testEnv.render()\n",
    "testEnv.action_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "def test_RL_models(model):\n",
    "    for dir, num in zip([\"data_easy\", \"data_medium\", \"data\"], [80, 24, 480]):\n",
    "        print(\"current data: \" + dir)\n",
    "        totalRew = 0\n",
    "        valDataset = Gridworld(dir = [dir], type = [\"val\"], lambda1=0, lambda2=0, load_optimal= False)\n",
    "        correct, total = 0,num*10\n",
    "        for task in range(int(total)):\n",
    "            if task % num == num-1:\n",
    "                print(f\"{(task+1) / total *100} %, running acc: {(correct*100)/(task+1)}, average reward: {totalRew / task}\")\n",
    "            currMDP = valDataset.reset()\n",
    "            done = False\n",
    "            steps = 0\n",
    "            while not done and steps < 50:\n",
    "                action = model.predict(currMDP, action_masks = valDataset.action_masks(), deterministic = True)[0]\n",
    "                currMDP, rew, done, _ = valDataset.step(action)\n",
    "                totalRew += rew\n",
    "                if rew > 0:\n",
    "                    correct += 1\n",
    "                steps += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CustomFeatureExtractorTorch(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.Space, features_dim: int = 32):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        self.conv1 = net.conv1\n",
    "        self.conv2 = net.conv2\n",
    "        self.conv3 = net.conv3\n",
    "        \n",
    "\n",
    "        #additional convolutions\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return x\n",
    "\n",
    "net_arch = [\n",
    "    32, 16, 8,\n",
    "    dict(vf = [16, 8, 4], pi = [16, 8, 4])\n",
    "]\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class = CustomFeatureExtractorTorch,\n",
    "    net_arch = net_arch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch = [\n",
    "    128, 64, 16, 8,\n",
    "    dict(vf = [8, 4, 2], pi = [8, 4, 2])\n",
    "]\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class = CustomFeatureExtractorTorch,\n",
    "    net_arch = net_arch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.9     |\n",
      "|    ep_rew_mean     | 0.33     |\n",
      "| time/              |          |\n",
      "|    fps             | 132      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.8         |\n",
      "|    ep_rew_mean          | -0.0505      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 4000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005245792 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.866       |\n",
      "|    explained_variance   | -0.28        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.015        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000733    |\n",
      "|    value_loss           | 0.136        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.9        |\n",
      "|    ep_rew_mean          | -0.123      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 6000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000307774 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.000745   |\n",
      "|    value_loss           | 0.083       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40.5         |\n",
      "|    ep_rew_mean          | -0.112       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 157          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 8000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007296883 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.896       |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0246       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    value_loss           | 0.0768       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.9         |\n",
      "|    ep_rew_mean          | 0.197        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 146          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007144501 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.87        |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0275       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    value_loss           | 0.0912       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.172       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 12000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002951967 |\n",
      "|    clip_fraction        | 9.77e-05    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.851      |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0321      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    value_loss           | 0.0566      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.7         |\n",
      "|    ep_rew_mean          | -0.0178      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 14000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025327904 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.837       |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0336       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 0.0642       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 23.7         |\n",
      "|    ep_rew_mean          | 0.329        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 16000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043485863 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.86        |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0133       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 0.0769       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36           |\n",
      "|    ep_rew_mean          | -0.0208      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 18000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068623447 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0234       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    value_loss           | 0.0598       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.1         |\n",
      "|    ep_rew_mean          | -0.048       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 143          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048529636 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.843       |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00171      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    value_loss           | 0.0668       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.9        |\n",
      "|    ep_rew_mean          | -0.0477     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 22000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008110822 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | -0.0958     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 0.0418      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 26.5         |\n",
      "|    ep_rew_mean          | 0.138        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 24000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057355296 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.858       |\n",
      "|    explained_variance   | -0.0144      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0017      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    value_loss           | 0.0457       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.4        |\n",
      "|    ep_rew_mean          | -0.0252     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 26000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006538555 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    value_loss           | 0.0533      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | 0.137        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 140          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 28000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048390115 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.869       |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0283       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    value_loss           | 0.0401       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 25.6         |\n",
      "|    ep_rew_mean          | 0.259        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 138          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048893834 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.825       |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0171      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 0.0654       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.4        |\n",
      "|    ep_rew_mean          | 0.256       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004790784 |\n",
      "|    clip_fraction        | 0.0498      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.838      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 0.0753      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.6         |\n",
      "|    ep_rew_mean          | 0.231        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 136          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 34000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044877967 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.818       |\n",
      "|    explained_variance   | 0.28         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00622      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 0.0529       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.6        |\n",
      "|    ep_rew_mean          | 0.356       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 36000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005771676 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00692    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    value_loss           | 0.0504      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 34.3       |\n",
      "|    ep_rew_mean          | 0.0618     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 38000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00574144 |\n",
      "|    clip_fraction        | 0.0616     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.807     |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.017      |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.00743   |\n",
      "|    value_loss           | 0.0799     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.8        |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007539852 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.838      |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0373      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    value_loss           | 0.0439      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 24.1         |\n",
      "|    ep_rew_mean          | 0.337        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 313          |\n",
      "|    total_timesteps      | 42000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077442285 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.806       |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0184       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00984     |\n",
      "|    value_loss           | 0.0645       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.3        |\n",
      "|    ep_rew_mean          | 0.139       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 44000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005787619 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.775      |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 0.0551      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.8        |\n",
      "|    ep_rew_mean          | -0.0085     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 46000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004231901 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.772      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 0.0433      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.7         |\n",
      "|    ep_rew_mean          | -0.0815      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 355          |\n",
      "|    total_timesteps      | 48000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043688095 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.748       |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0112       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 0.037        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 39.9        |\n",
      "|    ep_rew_mean          | -0.097      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006180915 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0411      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    value_loss           | 0.0503      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 42.8         |\n",
      "|    ep_rew_mean          | -0.0907      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 52000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037221434 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.785       |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.058        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 0.0579       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.4        |\n",
      "|    ep_rew_mean          | 0.236       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 397         |\n",
      "|    total_timesteps      | 54000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010225231 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00135    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    value_loss           | 0.0539      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.9        |\n",
      "|    ep_rew_mean          | 0.358       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 56000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005955315 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.73       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    value_loss           | 0.0901      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | 0.199       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 137         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 58000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008462288 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0812      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    value_loss           | 0.0681      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.8        |\n",
      "|    ep_rew_mean          | -0.189      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 430         |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007581496 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.799      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    value_loss           | 0.0654      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.8        |\n",
      "|    ep_rew_mean          | -0.309      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 62000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009211466 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00251     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 0.0513      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 39.7         |\n",
      "|    ep_rew_mean          | -0.0915      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 141          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 453          |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041044503 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.777       |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0236      |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    value_loss           | 0.0487       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.4         |\n",
      "|    ep_rew_mean          | 0.451        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 472          |\n",
      "|    total_timesteps      | 66000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045791185 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.704       |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0221       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 0.0601       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.191       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 486         |\n",
      "|    total_timesteps      | 68000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005192453 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.709      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0229      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 0.0599      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.3        |\n",
      "|    ep_rew_mean          | 0.402       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 502         |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004263195 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    value_loss           | 0.0713      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.8        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 72000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008059182 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    value_loss           | 0.0742      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 26.7       |\n",
      "|    ep_rew_mean          | 0.213      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 140        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 528        |\n",
      "|    total_timesteps      | 74000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00932192 |\n",
      "|    clip_fraction        | 0.0977     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.731     |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0675     |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00262   |\n",
      "|    value_loss           | 0.0626     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.5        |\n",
      "|    ep_rew_mean          | 0.327       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 76000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004451813 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0223      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 0.0523      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 36.3       |\n",
      "|    ep_rew_mean          | -0.0672    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 138        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 561        |\n",
      "|    total_timesteps      | 78000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00598127 |\n",
      "|    clip_fraction        | 0.0657     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.734     |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0104    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00256   |\n",
      "|    value_loss           | 0.0497     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35          |\n",
      "|    ep_rew_mean          | 0.024       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004374707 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.00943     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00586     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    value_loss           | 0.0631      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | 0.0573      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 82000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005463672 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0193      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    value_loss           | 0.0518      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.7        |\n",
      "|    ep_rew_mean          | -0.346      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 600         |\n",
      "|    total_timesteps      | 84000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006505571 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.729      |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00255     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    value_loss           | 0.0362      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.5        |\n",
      "|    ep_rew_mean          | -0.231      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 86000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006933482 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.737      |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.097       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 0.0808      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40.5         |\n",
      "|    ep_rew_mean          | -0.111       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 629          |\n",
      "|    total_timesteps      | 88000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076538203 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.719       |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0505       |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    value_loss           | 0.0465       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.1        |\n",
      "|    ep_rew_mean          | -0.157      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004978546 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0601      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 0.04        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 47.3       |\n",
      "|    ep_rew_mean          | -0.263     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 142        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 646        |\n",
      "|    total_timesteps      | 92000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00352703 |\n",
      "|    clip_fraction        | 0.0373     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.68      |\n",
      "|    explained_variance   | 0.588      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0176     |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0026    |\n",
      "|    value_loss           | 0.056      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 36.3         |\n",
      "|    ep_rew_mean          | -0.047       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 140          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 669          |\n",
      "|    total_timesteps      | 94000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034359088 |\n",
      "|    clip_fraction        | 0.0665       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.753       |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00087     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    value_loss           | 0.0403       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.1         |\n",
      "|    ep_rew_mean          | 0.443        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 687          |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051370705 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0138       |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 0.0911       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 22.3         |\n",
      "|    ep_rew_mean          | 0.303        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 138          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 708          |\n",
      "|    total_timesteps      | 98000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053495113 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.669       |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00423      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 0.0711       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.1         |\n",
      "|    ep_rew_mean          | 0.201        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 138          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 722          |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033422466 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.678       |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0055      |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 0.0978       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x7efe544a69d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalEnv = make_vec_env(Gridworld, n_envs= 4, env_kwargs={\"lambda1\" : 0, \"lambda2\" : 0, \"lambda3\": 1, \"dir\" : [\"data_easy\", \"generated_easy\", \"data_medium\", \"generated_med\", \"data\"], \"load_optimal\" : True})\n",
    "\n",
    "FinalModel = MaskablePPO(MaskableActorCriticPolicy, FinalEnv, policy_kwargs= policy_kwargs,  verbose = 1, n_steps= 500)\n",
    "\n",
    "FinalModel.learn(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 46.9     |\n",
      "|    ep_rew_mean     | 3.76     |\n",
      "| time/              |          |\n",
      "|    fps             | 688      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 144         |\n",
      "|    ep_rew_mean          | -0.269      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506195 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0617      |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8254/2522295804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFinalModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/ppo_mask/ppo_mask.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, use_masking)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_masking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/ppo_mask/ppo_mask.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps, use_masking)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# save final observation where user can get it, then reset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"terminal_observation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_from_buf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_rews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected you to pass keyword argument {key} into reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_reset_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGymStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8254/2861546178.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnextDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mnexti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datasets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mnexti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnexti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentMDP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMDP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnexti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda3\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FinalModel.learn(1e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current data: data_easy\n",
      "10.0 %, running acc: 78.75, average reward: 0.4895569620253207\n",
      "20.0 %, running acc: 76.25, average reward: 0.42216981132075326\n",
      "30.0 %, running acc: 75.83333333333333, average reward: 0.40502092050206223\n",
      "40.0 %, running acc: 75.9375, average reward: 0.40282131661437687\n",
      "50.0 %, running acc: 75.5, average reward: 0.3913533834585942\n",
      "60.0 %, running acc: 75.625, average reward: 0.39284968684754173\n",
      "70.0 %, running acc: 75.53571428571429, average reward: 0.389713774597434\n",
      "80.0 %, running acc: 76.40625, average reward: 0.409350547730773\n",
      "90.0 %, running acc: 75.83333333333333, average reward: 0.39760083449234174\n",
      "100.0 %, running acc: 74.5, average reward: 0.36921151439302985\n",
      "current data: data_medium\n",
      "10.0 %, running acc: 58.333333333333336, average reward: 0.03369565217391344\n",
      "20.0 %, running acc: 66.66666666666667, average reward: 0.20531914893616826\n",
      "30.0 %, running acc: 70.83333333333333, average reward: 0.28802816901408473\n",
      "40.0 %, running acc: 71.875, average reward: 0.30421052631579537\n",
      "50.0 %, running acc: 74.16666666666667, average reward: 0.3518907563025291\n",
      "60.0 %, running acc: 71.52777777777777, average reward: 0.2942307692307814\n",
      "70.0 %, running acc: 70.23809523809524, average reward: 0.26616766467067343\n",
      "80.0 %, running acc: 71.35416666666667, average reward: 0.29044502617802576\n",
      "90.0 %, running acc: 72.22222222222223, average reward: 0.30779069767442685\n",
      "100.0 %, running acc: 71.66666666666667, average reward: 0.2945606694560632\n",
      "current data: data\n",
      "10.0 %, running acc: 54.166666666666664, average reward: -0.1078810020876534\n",
      "20.0 %, running acc: 53.958333333333336, average reward: -0.11303441084466098\n",
      "30.0 %, running acc: 53.958333333333336, average reward: -0.11337734537880557\n",
      "40.0 %, running acc: 54.0625, average reward: -0.1112428348098864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11187/1372373952.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_RL_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinalModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_11187/4223023923.py\u001b[0m in \u001b[0;36mtest_RL_models\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrMDP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mcurrMDP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mtotalRew\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/ppo_mask/ppo_mask.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, mask, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/common/maskable/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, mask, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;31m# Convert to numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/common/maskable/policies.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, observation, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m         \u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction_masks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_masking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/common/maskable/policies.py\u001b[0m in \u001b[0;36m_get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[1;32m    204\u001b[0m         \u001b[0maction_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     def _predict(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/common/maskable/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, action_logits)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# Restructure shape to align with logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mreshaped_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskableCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreshaped_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/common/maskable/distributions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args, masks)\u001b[0m\n\u001b[1;32m     35\u001b[0m     ):\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_masking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`logits` parameter must be at least one-dimensional.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_RL_models(FinalModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalModel.save(\"RLModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnv = Gridworld(load_optimal= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' 'v' '#' '.']\n",
      "  ['#' '.' '.' '.']\n",
      "  ['#' 'O' '#' '#']\n",
      "  ['#' '.' '.' '.']]\n",
      "\n",
      " [['#' '.' '#' '.']\n",
      "  ['#' '.' '.' '.']\n",
      "  ['#' '.' '#' '#']\n",
      "  ['#' 'v' '.' '.']]]\n"
     ]
    }
   ],
   "source": [
    "curr = testEnv.reset()\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1]\n",
      "[[['#' '.' '#' '.']\n",
      "  ['#' '.' '.' '.']\n",
      "  ['#' '.' '#' '#']\n",
      "  ['#' 'v' '.' '.']]\n",
      "\n",
      " [['#' '.' '#' '.']\n",
      "  ['#' '.' '.' '.']\n",
      "  ['#' '.' '#' '#']\n",
      "  ['#' 'v' '.' '.']]]\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "a = FinalModel.predict(curr, action_masks= testEnv.action_masks(), deterministic= True)[0]\n",
    "curr, _, done, _ = testEnv.step(a)\n",
    "print(testEnv.action_masks())\n",
    "testEnv.render()\n",
    "if done:\n",
    "    print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
