{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch \n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from MDP import MDP\n",
    "\n",
    "import stable_baselines3\n",
    "import sb3_contrib\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['.' '.' '.' '#']\n",
      "  ['v' '#' '#' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.01\n",
      "[[['.' '.' '.' '#']\n",
      "  ['d' '#' '#' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.1\n",
      "[[['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.01\n",
      "[[['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n"
     ]
    }
   ],
   "source": [
    "#load MDP\n",
    "mdp = MDP(dir = \"data_medium\", type = \"val\", name = \"100595\")\n",
    "# show grid\n",
    "done = False\n",
    "for a in [\"move\", \"putMarker\", \"move\"]:\n",
    "    if done:\n",
    "        break\n",
    "    nextState, rew, done, b = mdp.sample_next_state_and_reward(a)\n",
    "    mdp.print_grid()\n",
    "    print(rew)\n",
    "mdp.print_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model with Imitation learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seq', 'task']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data tests\n",
    "os.listdir(\"datasets/data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171921\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "\n",
    "#numerical representation of actions\n",
    "getNumAction = {\n",
    "    \"move\" : 0,\n",
    "    \"turnRight\": 1,\n",
    "    \"turnLeft\" : 2,\n",
    "    \"pickMarker\": 3,\n",
    "    \"putMarker\" : 4,\n",
    "    \"finish\" : 5\n",
    "}\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    attributes:\n",
    "    dir : str list :=  accepted directories (data, data_easy, data_medium)\n",
    "    type : str list := train and/or val\n",
    "    grid : tensor := a tensor of all available grids\n",
    "    actions : tensor := vector of the optimal action for each\n",
    "    \"\"\"\n",
    "    def data_generator(self):\n",
    "        for dir in self.dir:\n",
    "            for type in self.type:\n",
    "                for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "                    i = re.sub(r\"\\D\", \"\", i)\n",
    "                    # load MDP and optimal sequence\n",
    "                    currMDP = MDP(dir = dir, type = type, name = str(i))\n",
    "\n",
    "                    with open(os.sep.join([\"datasets\", dir, type, \"seq\", str(i) + \"_seq.json\"])) as seq:\n",
    "                        sequence = json.load(seq)[\"sequence\"]\n",
    "                    \n",
    "                    for action in sequence:\n",
    "                        yield currMDP.get_current_state().copy(), action\n",
    "                        currMDP.get_next_state(action)\n",
    "\n",
    "\n",
    "    def __init__(self, dir = [\"data\", \"data_easy\", \"data_medium\"], type = [\"train\"]) -> None:\n",
    "        \"\"\"\n",
    "        dir : str list :=  accepted directories (data, data_easy, data_medium)\n",
    "        type : str list := train and/or val\n",
    "        \"\"\"\n",
    "        self.dir = dir\n",
    "        self.type = type\n",
    "        lstActionsAndGrids = list(self.data_generator())\n",
    "        self.grid = torch.tensor(np.array([x[0] for x in lstActionsAndGrids]) / 10, device= device)\n",
    "        self.actions = torch.tensor(np.array([getNumAction[x[1]] for x in lstActionsAndGrids]), device= device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.grid)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.grid[idx], self.actions[idx]\n",
    "\n",
    "trainDataset = Dataset()\n",
    "valDataset = Dataset(type = [\"val\"])\n",
    "print(len(trainDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Neural Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    input : 2 X 4 X 4 grid\n",
    "    label : Move [0;6]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # first layer: input\n",
    "        self.conv1 = nn.Conv2d(2, 8, 2)\n",
    "\n",
    "        #second layer : 2nd convolution\n",
    "        self.conv2 = nn.Conv2d(8, 16, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 16)\n",
    "\n",
    "        self.out = nn.Linear(16, 6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = self.out(x)\n",
    "    \n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(2, 8, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (out): Linear(in_features=16, out_features=6, bias=True)\n",
      ")\n",
      "number of parameters: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating model\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "print(f\"number of parameters: {len(params)}\")\n",
    "\n",
    "#loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "dataloader = data.DataLoader(trainDataset, BATCH_SIZE)\n",
    "validationLoader = data.DataLoader(valDataset, BATCH_SIZE)\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        lossVal = loss(outputs, labels)\n",
    "        lossVal.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += lossVal.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(dataloader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "  batch 1000 loss: 1.5867546260356904\n",
      "  batch 2000 loss: 1.5772992132902146\n",
      "  batch 3000 loss: 1.57220743227005\n",
      "  batch 4000 loss: 1.5755636262893677\n",
      "  batch 5000 loss: 1.551279238820076\n",
      "  batch 6000 loss: 1.3693251210451125\n",
      "  batch 7000 loss: 1.2637701690793037\n",
      "  batch 8000 loss: 0.9461072353720665\n",
      "  batch 9000 loss: 1.1730993755459787\n",
      "  batch 10000 loss: 1.18763502150774\n",
      "Loss train 1.18763502150774 validation 1.1625109910964966\n",
      "EPOCH 2\n",
      "  batch 1000 loss: 1.1649587237238883\n",
      "  batch 2000 loss: 1.1489830795526506\n",
      "  batch 3000 loss: 1.125676609158516\n",
      "  batch 4000 loss: 1.1138256943225862\n",
      "  batch 5000 loss: 1.0627977197170257\n",
      "  batch 6000 loss: 1.0368213463425637\n",
      "  batch 7000 loss: 1.0082797474861145\n",
      "  batch 8000 loss: 0.7566095046699047\n",
      "  batch 9000 loss: 0.8730689616501331\n",
      "  batch 10000 loss: 0.8604535292088985\n",
      "Loss train 0.8604535292088985 validation 0.8976699113845825\n",
      "EPOCH 3\n",
      "  batch 1000 loss: 0.9427970862686634\n",
      "  batch 2000 loss: 0.9329362818300724\n",
      "  batch 3000 loss: 0.9219413928985596\n",
      "  batch 4000 loss: 0.9176331174075604\n",
      "  batch 5000 loss: 0.8975191759169102\n",
      "  batch 6000 loss: 0.8888639718294143\n",
      "  batch 7000 loss: 0.870361383587122\n",
      "  batch 8000 loss: 0.6577659458070994\n",
      "  batch 9000 loss: 0.68063027985394\n",
      "  batch 10000 loss: 0.6887143757790327\n",
      "Loss train 0.6887143757790327 validation 1.1398416757583618\n",
      "EPOCH 4\n",
      "  batch 1000 loss: 1.061776250243187\n",
      "  batch 2000 loss: 0.81779256311059\n",
      "  batch 3000 loss: 0.8391024620831012\n",
      "  batch 4000 loss: 0.8255665362626314\n",
      "  batch 5000 loss: 0.8024080553352833\n",
      "  batch 6000 loss: 0.7827824807465077\n",
      "  batch 7000 loss: 0.8005957372188568\n",
      "  batch 8000 loss: 0.5471277444139123\n",
      "  batch 9000 loss: 0.7076382038593292\n",
      "  batch 10000 loss: 0.5723765011280775\n",
      "Loss train 0.5723765011280775 validation 0.7295156121253967\n",
      "EPOCH 5\n",
      "  batch 1000 loss: 0.7889404768943786\n",
      "  batch 2000 loss: 0.7811057926118374\n",
      "  batch 3000 loss: 0.828733379215002\n",
      "  batch 4000 loss: 0.7689641210734844\n",
      "  batch 5000 loss: 0.7516921632289887\n",
      "  batch 6000 loss: 0.7739350123405456\n",
      "  batch 7000 loss: 0.7348428990840912\n",
      "  batch 8000 loss: 0.5111000405997038\n",
      "  batch 9000 loss: 0.53453668532148\n",
      "  batch 10000 loss: 0.595092869348824\n",
      "Loss train 0.595092869348824 validation 0.7124248743057251\n",
      "EPOCH 6\n",
      "  batch 1000 loss: 0.7633378029316664\n",
      "  batch 2000 loss: 0.7451370739042759\n",
      "  batch 3000 loss: 0.7667906488776207\n",
      "  batch 4000 loss: 0.7387311749309301\n",
      "  batch 5000 loss: 0.7198730873018503\n",
      "  batch 6000 loss: 0.7929397583007812\n",
      "  batch 7000 loss: 0.71788205344975\n",
      "  batch 8000 loss: 0.48800186524167655\n",
      "  batch 9000 loss: 0.5369713275805116\n",
      "  batch 10000 loss: 0.505357095271349\n",
      "Loss train 0.505357095271349 validation 0.6889073848724365\n",
      "EPOCH 7\n",
      "  batch 1000 loss: 0.7663511619716883\n",
      "  batch 2000 loss: 0.7285690847337246\n",
      "  batch 3000 loss: 0.727579000979662\n",
      "  batch 4000 loss: 0.7868389904797077\n",
      "  batch 5000 loss: 0.7017208307236433\n",
      "  batch 6000 loss: 0.7077316254675389\n",
      "  batch 7000 loss: 0.7253578940182924\n",
      "  batch 8000 loss: 0.4743346749357879\n",
      "  batch 9000 loss: 0.5242848236784339\n",
      "  batch 10000 loss: 0.4803259174823761\n",
      "Loss train 0.4803259174823761 validation 0.677180290222168\n",
      "EPOCH 8\n",
      "  batch 1000 loss: 0.7934724024087191\n",
      "  batch 2000 loss: 0.7146345881819725\n",
      "  batch 3000 loss: 0.7061399975717068\n",
      "  batch 4000 loss: 0.7165704185068608\n",
      "  batch 5000 loss: 0.6997651776075363\n",
      "  batch 6000 loss: 0.7023007256686687\n",
      "  batch 7000 loss: 0.697470666974783\n",
      "  batch 8000 loss: 0.4936541434638202\n",
      "  batch 9000 loss: 0.4785743904449046\n",
      "  batch 10000 loss: 0.46959674441069366\n",
      "Loss train 0.46959674441069366 validation 0.6699371933937073\n",
      "EPOCH 9\n",
      "  batch 1000 loss: 0.7160958393216134\n",
      "  batch 2000 loss: 0.7056919844895602\n",
      "  batch 3000 loss: 0.7380239124298096\n",
      "  batch 4000 loss: 0.6858533615022898\n",
      "  batch 5000 loss: 0.6754764019697904\n",
      "  batch 6000 loss: 0.6808797397911549\n",
      "  batch 7000 loss: 0.741547427996993\n",
      "  batch 8000 loss: 0.4511367822699249\n",
      "  batch 9000 loss: 0.46893186112865803\n",
      "  batch 10000 loss: 0.44950376203656195\n",
      "Loss train 0.44950376203656195 validation 0.6538951396942139\n",
      "EPOCH 10\n",
      "  batch 1000 loss: 0.6961441910862922\n",
      "  batch 2000 loss: 0.682411680072546\n",
      "  batch 3000 loss: 0.7178135371804237\n",
      "  batch 4000 loss: 0.6706912604868412\n",
      "  batch 5000 loss: 0.6642475631833077\n",
      "  batch 6000 loss: 0.670757040783763\n",
      "  batch 7000 loss: 0.6773020864352584\n",
      "  batch 8000 loss: 0.4415531814917922\n",
      "  batch 9000 loss: 0.4398096995800734\n",
      "  batch 10000 loss: 0.44436478896066545\n",
      "Loss train 0.44436478896066545 validation 0.6642895936965942\n",
      "EPOCH 11\n",
      "  batch 1000 loss: 0.6860358992218971\n",
      "  batch 2000 loss: 0.6635495445728302\n",
      "  batch 3000 loss: 0.6681666147261858\n",
      "  batch 4000 loss: 0.6861444125249981\n",
      "  batch 5000 loss: 0.6489648937433958\n",
      "  batch 6000 loss: 0.6563216162770986\n",
      "  batch 7000 loss: 0.6667455956786871\n",
      "  batch 8000 loss: 0.4405953517444432\n",
      "  batch 9000 loss: 0.42899899059347807\n",
      "  batch 10000 loss: 0.4461747381463647\n",
      "Loss train 0.4461747381463647 validation 0.6435109376907349\n",
      "EPOCH 12\n",
      "  batch 1000 loss: 0.6894412946254015\n",
      "  batch 2000 loss: 0.6546723552495242\n",
      "  batch 3000 loss: 0.6939007934182883\n",
      "  batch 4000 loss: 0.6699340099543333\n",
      "  batch 5000 loss: 0.6362273322790861\n",
      "  batch 6000 loss: 0.645596314817667\n",
      "  batch 7000 loss: 0.6480612075850367\n",
      "  batch 8000 loss: 0.4293407696224749\n",
      "  batch 9000 loss: 0.42563905114308\n",
      "  batch 10000 loss: 0.40715161566995084\n",
      "Loss train 0.40715161566995084 validation 0.6554186344146729\n",
      "EPOCH 13\n",
      "  batch 1000 loss: 0.6730516089349985\n",
      "  batch 2000 loss: 0.6480780834704638\n",
      "  batch 3000 loss: 0.6576969313174487\n",
      "  batch 4000 loss: 0.6301652674674988\n",
      "  batch 5000 loss: 0.6495293142050504\n",
      "  batch 6000 loss: 0.6320414317697287\n",
      "  batch 7000 loss: 0.6883846061974764\n",
      "  batch 8000 loss: 0.4320533713437617\n",
      "  batch 9000 loss: 0.39788588710129263\n",
      "  batch 10000 loss: 0.396174091193825\n",
      "Loss train 0.396174091193825 validation 0.6209050416946411\n",
      "EPOCH 14\n",
      "  batch 1000 loss: 0.6845658660531044\n",
      "  batch 2000 loss: 0.632714817866683\n",
      "  batch 3000 loss: 0.6316804026812315\n",
      "  batch 4000 loss: 0.6228683900684119\n",
      "  batch 5000 loss: 0.6481421398073435\n",
      "  batch 6000 loss: 0.6177336042225361\n",
      "  batch 7000 loss: 0.6244882041588425\n",
      "  batch 8000 loss: 0.4083986030537635\n",
      "  batch 9000 loss: 0.4016095224767923\n",
      "  batch 10000 loss: 0.3878031790647656\n",
      "Loss train 0.3878031790647656 validation 0.6274697780609131\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "writer = SummaryWriter(\"runs/imitation_learning_{}\".format(timestamp))\n",
    "epoch_num = 0\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "EPOCHS = 14\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH {}\".format(epoch_num + 1))\n",
    "\n",
    "    net.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_num, writer)\n",
    "\n",
    "    net.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(validationLoader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vout = net(vinputs)\n",
    "        vloss = loss(vout, vlabels)\n",
    "        running_vloss += vloss\n",
    "    avg_vloss = running_vloss / (i+1)\n",
    "    print(f\"Loss train {avg_loss} validation {avg_vloss}\")\n",
    "\n",
    "\n",
    "    writer.add_scalars(\"Training Loss\", {\"Training\" : avg_loss, \"validation\" : avg_vloss})\n",
    "    writer.flush()\n",
    "\n",
    "    epoch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['>' '.' '.' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.01\n",
      "[[['.' '>' '.' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.015\n",
      "[[['.' '.' '>' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.017499999999999998\n",
      "[[['.' '.' '.' 'r']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: turnLeft, reward: 0.017499999999999998\n",
      "[[['.' '.' '.' 'u']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.045, 5, False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "actions = [\"move\", \"turnRight\", \"turnLeft\", \"pickMarker\", \"putMarker\", \"finish\"]\n",
    "\n",
    "testMDP = MDP(dir = \"data\", type = \"val\", name = \"100112\")\n",
    "\n",
    "def apply_to_grid(MDP, show_grid):\n",
    "    reward = 0\n",
    "    steps = 0\n",
    "    if show_grid:\n",
    "        MDP.print_grid()\n",
    "    while True:\n",
    "        current_grid = torch.tensor(MDP.get_current_state(), device= device) / 10\n",
    "        out = net(current_grid.unsqueeze(0))\n",
    "        nextAction = actions[torch.argmax(out)]\n",
    "        reward += MDP.gamma**steps * MDP.reward(nextAction)\n",
    "        steps += 1\n",
    "        if MDP.get_next_state(nextAction) == \"Terminal\" or steps > 100:\n",
    "            return reward, steps, MDP.task_solved()\n",
    "        if show_grid:\n",
    "            print(\"action: {}, reward: {}\".format(nextAction, reward))\n",
    "            MDP.print_grid()\n",
    "\n",
    "\n",
    "apply_to_grid(testMDP, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks solved with only imitation learning:\n",
      "Total : 2180, accuracy: 0.126523505513639\n"
     ]
    }
   ],
   "source": [
    "# check accuracy of solved tasks\n",
    "sucesses = 0\n",
    "for dir in [\"data\", \"data_easy\", \"data_medium\"]:\n",
    "    for type in [\"val\"]:\n",
    "        for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "            i = re.sub(r\"\\D\", \"\", i)\n",
    "            curr_MDP = MDP(dir, type, i)\n",
    "            if apply_to_grid(curr_MDP, False)[-1]:\n",
    "                sucesses += 1\n",
    "\n",
    "print(\"tasks solved with only imitation learning:\")\n",
    "print(f\"Total : {sucesses}, accuracy: {sucesses / len(valDataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clearly seen here, imitation learning with the limited amount of training data is not able to solve most of the provided tasks. Therefore, in the following I will use the described PPO approach and after that will create the final model that uses imitation learning to initiate the model and then trains it with maskless PPO to achieve the best possible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['<' '#' '#' '.']\n",
      "  ['#' '.' '#' '#']\n",
      "  ['#' '#' '#' '#']\n",
      "  ['#' '#' '.' '#']]\n",
      "\n",
      " [['<' '#' '#' '.']\n",
      "  ['#' '.' '#' '#']\n",
      "  ['#' '#' '#' '#']\n",
      "  ['#' '#' '.' '#']]]\n"
     ]
    }
   ],
   "source": [
    "# test generated MDPs\n",
    "test = np.random.randint(1, 1e5)\n",
    "\n",
    "genMDP = MDP(\"generated\", \"train\", str(test))\n",
    "\n",
    "genMDP.print_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom environment\n",
    "from gym import spaces\n",
    "\n",
    "class Gridworld(gym.Env):\n",
    "\n",
    "    metadata = {\"render.modes\" : [\"human\"]}\n",
    "\n",
    "    def MDP_generator(self):\n",
    "        while True:\n",
    "            for dir in self.dir:\n",
    "                for type in self.type:\n",
    "                    for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "                        i = re.sub(r\"\\D\", \"\", i)\n",
    "                        yield dir, type, i\n",
    "\n",
    "    def __init__(self, dir = [\"data\", \"data_easy\", \"data_medium\"], type = [\"train\"], lambda1 = 0.01, lambda2 = 0.1, lambda3 = 1) -> None:\n",
    "        super(Gridworld, self).__init__()\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(low = 0, high = 10, shape = (2, 4, 4))\n",
    "\n",
    "        #available MDPs\n",
    "        self.dir = dir\n",
    "        self.type = type\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.lambda3 = lambda3\n",
    "\n",
    "\n",
    "\n",
    "        self.next_MDP = self.MDP_generator()\n",
    "        self.actions = [\"move\", \"turnLeft\", \"turnRight\", \"pickMarker\", \"putMarker\", \"finish\"]\n",
    "\n",
    "    def reset(self):\n",
    "        self.nextDir, self.nextType, self.nexti =  next(self.next_MDP)\n",
    "        self.currentMDP = MDP(self.nextDir, self.nextType, self.nexti, lambda1= self.lambda1, lambda2 = self.lambda2, lambda3 =self.lambda3)\n",
    "        return self.currentMDP.get_current_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.currentMDP.sample_next_state_and_reward(self.actions[action])\n",
    "        \n",
    "    def render(self):\n",
    "        self.currentMDP.print_grid()\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def action_masks(self):\n",
    "        return self.currentMDP.action_mask()\n",
    "\n",
    "    # functions bellow are only used for inheritance \n",
    "    def get_MDP(self):\n",
    "        return self.currentMDP\n",
    "\n",
    "    def get_MDP_name(self):\n",
    "        return self.nextDir, self.nextType, self.nexti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "testEnv = Gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53     |\n",
      "|    ep_rew_mean     | -0.384   |\n",
      "| time/              |          |\n",
      "|    fps             | 4664     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.84        |\n",
      "|    ep_rew_mean          | -0.272      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2487        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.067049526 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -1.52       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00382    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0547     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.31        |\n",
      "|    ep_rew_mean          | -0.154      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2120        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032305546 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -0.332      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0537     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.87        |\n",
      "|    ep_rew_mean          | -0.119      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2001        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024943938 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -0.394      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0276     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 0.0574      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76        |\n",
      "|    ep_rew_mean          | -0.088      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1933        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018737532 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.71       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00803    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69        |\n",
      "|    ep_rew_mean          | -0.075      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1882        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014659116 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.872      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0709     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.0117      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.98        |\n",
      "|    ep_rew_mean          | -0.046      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1854        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017766759 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.891      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 0.00771     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54        |\n",
      "|    ep_rew_mean          | -0.048      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1832        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019406248 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.926      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0396     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    value_loss           | 0.00434     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.92        |\n",
      "|    ep_rew_mean          | -0.032      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025775779 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -0.401      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0575     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0528     |\n",
      "|    value_loss           | 0.00347     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.85        |\n",
      "|    ep_rew_mean          | -0.017      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1795        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025487471 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | -0.262      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0884     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    value_loss           | 0.00328     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81        |\n",
      "|    ep_rew_mean          | -0.014      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1781        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023201171 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | -0.251      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.07       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 0.00249     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.94        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1771        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018107843 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.72       |\n",
      "|    explained_variance   | -0.128      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.00202     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.92        |\n",
      "|    ep_rew_mean          | -0.004      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1769        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012312788 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | -0.165      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00126    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.00142     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81        |\n",
      "|    ep_rew_mean          | -0.003      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1767        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012321491 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | -0.587      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.000424    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41        |\n",
      "|    ep_rew_mean          | -0.002      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1763        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009046601 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.000782    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.95        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1752        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011041418 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.54       |\n",
      "|    explained_variance   | -0.457      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.000165    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.03        |\n",
      "|    ep_rew_mean          | -0.002      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1739        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010586654 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | -0.244      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000892    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000209    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.98        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1728        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012334334 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | -0.368      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00752     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 6.19e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.2         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1725        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012339989 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | -0.0909     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.000179    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.93        |\n",
      "|    ep_rew_mean          | -0.001      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1718        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010442607 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.604      |\n",
      "|    explained_variance   | -0.338      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 3.39e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.34        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1716        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015234548 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0441     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 3.24e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.6         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1713        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018277075 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | -0.205      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0339     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 2.62e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.83        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1711        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013504181 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | -0.355      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0321     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 1.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.2         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018164074 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | -1.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 4.68e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.53        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014087643 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | -0.137      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0333     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 5.92e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.76        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016080918 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.689      |\n",
      "|    explained_variance   | -0.484      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0554     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 4.95e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.63        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011534102 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.689      |\n",
      "|    explained_variance   | -8.85e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.00864     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.27        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1707        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012842584 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | -0.0358     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0268      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.00819     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.58         |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1705         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123186335 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.683       |\n",
      "|    explained_variance   | -0.138       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0477      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    value_loss           | 0.00312      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.56        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1704        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014000794 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.672      |\n",
      "|    explained_variance   | -1.23       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0072     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.00061     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.25        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1702        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196265 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | -0.0843     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0339     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.00129     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.43        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1700        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013138529 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | -0.336      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00246     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.00107     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.24        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1701        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012056604 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | -0.0864     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    value_loss           | 0.00152     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.71       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1700       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01688756 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.71      |\n",
      "|    explained_variance   | -11.8      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0295    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 2.2e-05    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.64        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012747726 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | -5.4        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0223     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 1.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.44        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011837827 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | -0.0286     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.031      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.000507    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.9         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1697        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012203876 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | -0.0251     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    value_loss           | 0.000732    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.48       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1698       |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01744307 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.741     |\n",
      "|    explained_variance   | -0.267     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00936   |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    value_loss           | 0.000613   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.2         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013428509 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | -5.91       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 1.98e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.7         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012138868 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | -0.0312     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    value_loss           | 0.000783    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.21       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1699       |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 335872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01855794 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.697     |\n",
      "|    explained_variance   | -4.98      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0134    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    value_loss           | 1.79e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.01        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016865842 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.712      |\n",
      "|    explained_variance   | -9.78       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 2.91e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.46        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013537653 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | -0.0212     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00747     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 3.01e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.98        |\n",
      "|    ep_rew_mean          | -0.011      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023850935 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | -8.7        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0354     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 1.54e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.37        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010772362 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | -0.00115    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 0.00489     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.01        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013096693 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | -0.146      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.0035      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.34        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016081229 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | -1.08       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0194      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000464    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.19       |\n",
      "|    ep_rew_mean          | -0.001     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1699       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01088498 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.606     |\n",
      "|    explained_variance   | 0.0258     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.041     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00869   |\n",
      "|    value_loss           | 0.00246    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.26       |\n",
      "|    ep_rew_mean          | -0.001     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1699       |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 236        |\n",
      "|    total_timesteps      | 401408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01326372 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.631     |\n",
      "|    explained_variance   | -0.171     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0267    |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    value_loss           | 0.000978   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.95        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014413526 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | -0.304      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.032      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.000171    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.46        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012520941 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | -0.0083     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.00126     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.34        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011596083 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | -11.5       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00918     |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    value_loss           | 3.88e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.65        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1697        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015978072 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.614      |\n",
      "|    explained_variance   | -1.64       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00839     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    value_loss           | 4.13e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.44        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1697        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011448194 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | -3.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0145     |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 5.98e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.73        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1696        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013229883 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.563      |\n",
      "|    explained_variance   | -0.783      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00273    |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    value_loss           | 1.65e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.87        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1696        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009509501 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | -0.742      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 1.62e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.88        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1695        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013198145 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | -0.0517     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00331     |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    value_loss           | 2.34e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.14        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1695        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014449965 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.508      |\n",
      "|    explained_variance   | -0.0339     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.36       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1695       |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 483328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01750058 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.585     |\n",
      "|    explained_variance   | -0.00424   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0264    |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 0.000684   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.15        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1695        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025704125 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | -1.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00988    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.73e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.27        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1695        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011511356 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | -0.401      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00334     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 2.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.65        |\n",
      "|    ep_rew_mean          | -0.001      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1694        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018516967 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.578      |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00988    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 3.08e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f3f2d341d00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_vec_env(Gridworld, n_envs= 4, env_kwargs={\"lambda1\" : 0})\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose = 1, gamma= 1)\n",
    "model.learn(5 * 1e5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['.' '^' '.' '.']\n",
      "  ['.' '#' '.' '#']]\n",
      "\n",
      " [['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['v' '.' '.' '.']\n",
      "  ['.' '#' '.' '#']]]\n"
     ]
    }
   ],
   "source": [
    "test = testEnv.reset()\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0 False\n",
      "[[['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['.' '>' '.' '.']\n",
      "  ['.' '#' '.' '#']]\n",
      "\n",
      " [['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['v' '.' '.' '.']\n",
      "  ['.' '#' '.' '#']]]\n"
     ]
    }
   ],
   "source": [
    "action = model.predict(test, deterministic= True)[0]\n",
    "print(action)\n",
    "test, rew, done, _ = testEnv.step(action)\n",
    "print(rew, done)\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_RL_models(model):\n",
    "    valDataset = Gridworld(type = [\"val\"])\n",
    "    correct, total = 0,5000\n",
    "    for task in range(int(total)):\n",
    "        if task % 1000 == 999:\n",
    "            print(f\"{(task+1) / total *100} %\")\n",
    "        currMDP = valDataset.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        while not done and steps < 10:\n",
    "            action = model.predict(currMDP, action_masks = valDataset.action_masks(), deterministic = True)[0]\n",
    "            currMDP, rew, done, _ = valDataset.step(action)\n",
    "            if rew == 1:\n",
    "                correct += 1\n",
    "            steps += 1\n",
    "            \n",
    "            \n",
    "    print(f\"correct : {correct}, accuracy: {(correct*100)/total } %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8088/3237607495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_RL_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_RL_models(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal PPO model performs even worse then the Imitation learning model. This could be improved with some tuning, but I instead will focus on the maskable PPO model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maskable PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.9     |\n",
      "|    ep_rew_mean     | -0.161   |\n",
      "| time/              |          |\n",
      "|    fps             | 5394     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.3        |\n",
      "|    ep_rew_mean          | -0.181      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2414        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012206229 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -2.36       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00401    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0364      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.7        |\n",
      "|    ep_rew_mean          | -0.189      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2045        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011662807 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.856      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0238     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.0233      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.6        |\n",
      "|    ep_rew_mean          | -0.133      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1893        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012467567 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.172      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.0253      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | -0.0993     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012883643 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.00597     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00633    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.024       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | 0.0311      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1775        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013237604 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.0358      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.0279      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0547      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1744        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013382076 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00838    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.0313      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x7fb7f991a9a0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskEnv = make_vec_env(Gridworld, n_envs = 8)\n",
    "\n",
    "modelMask = MaskablePPO(MaskableActorCriticPolicy, maskEnv, verbose = 1, gamma = 1)\n",
    "modelMask.learn(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnv = Gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' '.' '.' '#']\n",
      "  ['#' '.' '#' '.']\n",
      "  ['.' '^' 'O' '.']\n",
      "  ['.' '.' '#' '.']]\n",
      "\n",
      " [['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]]\n"
     ]
    }
   ],
   "source": [
    "test = testEnv.reset()\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1 True\n",
      "[[['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]\n",
      "\n",
      " [['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]]\n"
     ]
    }
   ],
   "source": [
    "action = modelMask.predict(test, action_masks=testEnv.action_masks(), deterministic= True)[0]\n",
    "print(action)\n",
    "test, rew, done, _ = testEnv.step(action)\n",
    "print(rew, done)\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999.0001 %\n",
      "1999.0001 %\n",
      "2999.0001 %\n",
      "3999.0001 %\n",
      "4999.0001 %\n",
      "5999.0001 %\n",
      "6999.0001 %\n",
      "7999.0001 %\n",
      "8999.0001 %\n",
      "9999.0001 %\n",
      "correct : 13, accuracy: 0.13 %\n"
     ]
    }
   ],
   "source": [
    "test_RL_models(modelMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally I will try using a action mask that forces the agent to use the finish command if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridworldForcedFinished(Gridworld):\n",
    "    def __init__(self, dir=[\"data\", \"data_easy\", \"data_medium\"], type=[\"train\"], lambda1=0.01, lambda2=0.1, lambda3=1) -> None:\n",
    "        super().__init__(dir, type, lambda1, lambda2, lambda3)\n",
    "\n",
    "    def action_masks(self):\n",
    "        mat = super().get_MDP().get_current_state()\n",
    "        if np.array_equal(mat[0], mat[1]):\n",
    "            return np.array([0,0,0,0,0,1])\n",
    "\n",
    "        return super().action_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]\n",
      "\n",
      " [['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testEnv = GridworldForcedFinished()\n",
    "testEnv.reset()\n",
    "testEnv.step(0)\n",
    "testEnv.render()\n",
    "testEnv.action_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10       |\n",
      "|    ep_rew_mean     | -0.073   |\n",
      "| time/              |          |\n",
      "|    fps             | 4343     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8088/955931675.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodelForcedFinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskablePPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaskableActorCriticPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvForcedFinish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodelForcedFinish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/ppo_mask/ppo_mask.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, use_masking)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_masking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/ppo_mask/ppo_mask.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps, use_masking)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0maction_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/common/maskable/policies.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction_masks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_masking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/common/maskable/distributions.py\u001b[0m in \u001b[0;36mapply_masking\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_masking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Must set distribution parameters\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_masking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sb3_contrib/common/maskable/distributions.py\u001b[0m in \u001b[0;36mapply_masking\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Reinitialize with updated logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# self.probs may already be cached, so we must force an update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     raise ValueError(\n\u001b[1;32m     56\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "envForcedFinish = make_vec_env(GridworldForcedFinished, n_envs=8, env_kwargs={\"lambda1\" : 0})\n",
    "\n",
    "modelForcedFinish = MaskablePPO(MaskableActorCriticPolicy, envForcedFinish, verbose= 1, gamma= 1)\n",
    "modelForcedFinish.learn(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['.' '#' '.' '.']\n",
      "  ['.' '#' '<' '#']\n",
      "  ['.' '#' '.' '.']\n",
      "  ['.' '#' '.' '.']]\n",
      "\n",
      " [['.' '#' '.' '.']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' 'v' '.']\n",
      "  ['.' '#' '.' '.']]]\n"
     ]
    }
   ],
   "source": [
    "test = testEnv.reset()\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0 False\n",
      "[[['.' '#' '.' '.']\n",
      "  ['.' '#' 'v' '#']\n",
      "  ['.' '#' '.' '.']\n",
      "  ['.' '#' '.' '.']]\n",
      "\n",
      " [['.' '#' '.' '.']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' 'v' '.']\n",
      "  ['.' '#' '.' '.']]]\n"
     ]
    }
   ],
   "source": [
    "action = modelForcedFinish.predict(test, action_masks=testEnv.action_masks(), deterministic= True)[0]\n",
    "print(action)\n",
    "test, rew, done, _ = testEnv.step(action)\n",
    "print(rew, done)\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_RL_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8088/2000142741.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_RL_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelForcedFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_RL_models' is not defined"
     ]
    }
   ],
   "source": [
    "test_RL_models(modelForcedFinish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy did improve, but it is still far from perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imitation learning with PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = {\"move\" : 0,\n",
    "           \"turnLeft\" : 1,\n",
    "           \"turnRight\": 2,\n",
    "           \"pickMarker\": 3,\n",
    "           \"putMarker\": 4,\n",
    "           \"finish\": 5}\n",
    "\n",
    "\n",
    "class GridworldImitation(Gridworld):\n",
    "    \"\"\"\n",
    "    Gridworld that applies the action mask by forcing the agent to take the optimal action. This is used to kickstart the training of an agent for randomly generated tasks.\n",
    "    NOTE: can only be used for train and val data.\n",
    "    NOTE: Lambda 1 is set to 0\n",
    "    \"\"\"\n",
    "    def __init__(self, dir=[\"data\", \"data_easy\", \"data_medium\"], type=[\"train\"], lambda1=0, lambda2=0.1, lambda3=1) -> None:\n",
    "        super().__init__(dir, type, lambda1, lambda2, lambda3)\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        res = super().reset()\n",
    "        dir, type, i = super().get_MDP_name()\n",
    "        with open(os.sep.join([\"datasets\", dir, type, \"seq\", i + \"_seq.json\"])) as grid:\n",
    "            grid = json.load(grid)\n",
    "            self.optimal_seq = grid[\"sequence\"]\n",
    "            # current step\n",
    "            assert self.optimal_seq[-1] == \"finish\"\n",
    "            self.n = 0\n",
    "        return res\n",
    "\n",
    "    def action_masks(self):\n",
    "        mask = np.zeros(6)\n",
    "        mask[actions[self.optimal_seq[self.n]]] = 1\n",
    "        self.n += 1\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5.84     |\n",
      "|    ep_rew_mean     | 0.896    |\n",
      "| time/              |          |\n",
      "|    fps             | 4279     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5         |\n",
      "|    ep_rew_mean          | 0.884     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1666      |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.775    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00143   |\n",
      "|    n_updates            | 14        |\n",
      "|    policy_gradient_loss | -5.19e-10 |\n",
      "|    value_loss           | 0.0304    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.92      |\n",
      "|    ep_rew_mean          | 1.07      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1384      |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.439    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000705  |\n",
      "|    n_updates            | 28        |\n",
      "|    policy_gradient_loss | -4.23e-10 |\n",
      "|    value_loss           | 0.0158    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.8      |\n",
      "|    ep_rew_mean          | 1.04     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1272     |\n",
      "|    iterations           | 4        |\n",
      "|    time_elapsed         | 51       |\n",
      "|    total_timesteps      | 65536    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.614   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000811 |\n",
      "|    n_updates            | 42       |\n",
      "|    policy_gradient_loss | 2.26e-10 |\n",
      "|    value_loss           | 0.0131   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.8      |\n",
      "|    ep_rew_mean          | 0.9      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1219     |\n",
      "|    iterations           | 5        |\n",
      "|    time_elapsed         | 67       |\n",
      "|    total_timesteps      | 81920    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.702   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000838 |\n",
      "|    n_updates            | 56       |\n",
      "|    policy_gradient_loss | 8.89e-11 |\n",
      "|    value_loss           | 0.0112   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.2      |\n",
      "|    ep_rew_mean          | 1.05     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1187     |\n",
      "|    iterations           | 6        |\n",
      "|    time_elapsed         | 82       |\n",
      "|    total_timesteps      | 98304    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.618   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000748 |\n",
      "|    n_updates            | 70       |\n",
      "|    policy_gradient_loss | 1.39e-10 |\n",
      "|    value_loss           | 0.0115   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.44     |\n",
      "|    ep_rew_mean          | 1.04     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1166     |\n",
      "|    iterations           | 7        |\n",
      "|    time_elapsed         | 98       |\n",
      "|    total_timesteps      | 114688   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.486   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00098  |\n",
      "|    n_updates            | 84       |\n",
      "|    policy_gradient_loss | 1.83e-10 |\n",
      "|    value_loss           | 0.0148   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.96     |\n",
      "|    ep_rew_mean          | 1.05     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1147     |\n",
      "|    iterations           | 8        |\n",
      "|    time_elapsed         | 114      |\n",
      "|    total_timesteps      | 131072   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.918   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000809 |\n",
      "|    n_updates            | 98       |\n",
      "|    policy_gradient_loss | -8.4e-11 |\n",
      "|    value_loss           | 0.0101   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.52      |\n",
      "|    ep_rew_mean          | 0.524     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1133      |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 130       |\n",
      "|    total_timesteps      | 147456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.743    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000975  |\n",
      "|    n_updates            | 112       |\n",
      "|    policy_gradient_loss | -6.54e-11 |\n",
      "|    value_loss           | 0.0104    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.16     |\n",
      "|    ep_rew_mean          | 1.06     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1121     |\n",
      "|    iterations           | 10       |\n",
      "|    time_elapsed         | 146      |\n",
      "|    total_timesteps      | 163840   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.619   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000775 |\n",
      "|    n_updates            | 126      |\n",
      "|    policy_gradient_loss | 1.63e-10 |\n",
      "|    value_loss           | 0.0104   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.56      |\n",
      "|    ep_rew_mean          | 1.06      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1115      |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 161       |\n",
      "|    total_timesteps      | 180224    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.703    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000504  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -3.19e-10 |\n",
      "|    value_loss           | 0.0103    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.16      |\n",
      "|    ep_rew_mean          | 0.704     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1110      |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 177       |\n",
      "|    total_timesteps      | 196608    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.723    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000715  |\n",
      "|    n_updates            | 154       |\n",
      "|    policy_gradient_loss | -1.95e-13 |\n",
      "|    value_loss           | 0.0125    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.04      |\n",
      "|    ep_rew_mean          | 0.896     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1106      |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 192       |\n",
      "|    total_timesteps      | 212992    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.889    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000564  |\n",
      "|    n_updates            | 168       |\n",
      "|    policy_gradient_loss | -1.25e-10 |\n",
      "|    value_loss           | 0.00969   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.52     |\n",
      "|    ep_rew_mean          | 0.876    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1102     |\n",
      "|    iterations           | 14       |\n",
      "|    time_elapsed         | 208      |\n",
      "|    total_timesteps      | 229376   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.805   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000767 |\n",
      "|    n_updates            | 182      |\n",
      "|    policy_gradient_loss | 5.35e-11 |\n",
      "|    value_loss           | 0.0112   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.8      |\n",
      "|    ep_rew_mean          | 1.07     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1099     |\n",
      "|    iterations           | 15       |\n",
      "|    time_elapsed         | 223      |\n",
      "|    total_timesteps      | 245760   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.609   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000483 |\n",
      "|    n_updates            | 196      |\n",
      "|    policy_gradient_loss | 5.83e-11 |\n",
      "|    value_loss           | 0.00958  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.24      |\n",
      "|    ep_rew_mean          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1095      |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 239       |\n",
      "|    total_timesteps      | 262144    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.768    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000844  |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -4.32e-10 |\n",
      "|    value_loss           | 0.00979   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.28     |\n",
      "|    ep_rew_mean          | 0.736    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1091     |\n",
      "|    iterations           | 17       |\n",
      "|    time_elapsed         | 255      |\n",
      "|    total_timesteps      | 278528   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.821   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000866 |\n",
      "|    n_updates            | 224      |\n",
      "|    policy_gradient_loss | 3.29e-10 |\n",
      "|    value_loss           | 0.011    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.44     |\n",
      "|    ep_rew_mean          | 0.716    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1089     |\n",
      "|    iterations           | 18       |\n",
      "|    time_elapsed         | 270      |\n",
      "|    total_timesteps      | 294912   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.793   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00123  |\n",
      "|    n_updates            | 238      |\n",
      "|    policy_gradient_loss | 1.95e-12 |\n",
      "|    value_loss           | 0.0113   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5         |\n",
      "|    ep_rew_mean          | 0.908     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1087      |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 286       |\n",
      "|    total_timesteps      | 311296    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.667    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000696  |\n",
      "|    n_updates            | 252       |\n",
      "|    policy_gradient_loss | -2.69e-10 |\n",
      "|    value_loss           | 0.0116    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.4      |\n",
      "|    ep_rew_mean          | 0.9      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1084     |\n",
      "|    iterations           | 20       |\n",
      "|    time_elapsed         | 302      |\n",
      "|    total_timesteps      | 327680   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.822   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000827 |\n",
      "|    n_updates            | 266      |\n",
      "|    policy_gradient_loss | -1.4e-10 |\n",
      "|    value_loss           | 0.0104   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.8       |\n",
      "|    ep_rew_mean          | 0.9       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1079      |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 318       |\n",
      "|    total_timesteps      | 344064    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.795    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000896  |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -3.68e-10 |\n",
      "|    value_loss           | 0.0102    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.52     |\n",
      "|    ep_rew_mean          | 1.09     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1070     |\n",
      "|    iterations           | 22       |\n",
      "|    time_elapsed         | 336      |\n",
      "|    total_timesteps      | 360448   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -1.24    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00102  |\n",
      "|    n_updates            | 294      |\n",
      "|    policy_gradient_loss | 3.07e-10 |\n",
      "|    value_loss           | 0.0105   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.08      |\n",
      "|    ep_rew_mean          | 0.716     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1068      |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 352       |\n",
      "|    total_timesteps      | 376832    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.939    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000888  |\n",
      "|    n_updates            | 308       |\n",
      "|    policy_gradient_loss | -1.35e-10 |\n",
      "|    value_loss           | 0.0129    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.4       |\n",
      "|    ep_rew_mean          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1068      |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 368       |\n",
      "|    total_timesteps      | 393216    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.799    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000772  |\n",
      "|    n_updates            | 322       |\n",
      "|    policy_gradient_loss | -3.36e-10 |\n",
      "|    value_loss           | 0.0124    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.84     |\n",
      "|    ep_rew_mean          | 0.9      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1067     |\n",
      "|    iterations           | 25       |\n",
      "|    time_elapsed         | 383      |\n",
      "|    total_timesteps      | 409600   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.573   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.000776 |\n",
      "|    n_updates            | 336      |\n",
      "|    policy_gradient_loss | 2.35e-10 |\n",
      "|    value_loss           | 0.0118   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.08     |\n",
      "|    ep_rew_mean          | 1.07     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1067     |\n",
      "|    iterations           | 26       |\n",
      "|    time_elapsed         | 399      |\n",
      "|    total_timesteps      | 425984   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.751   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00137  |\n",
      "|    n_updates            | 350      |\n",
      "|    policy_gradient_loss | 4.07e-11 |\n",
      "|    value_loss           | 0.0104   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.52     |\n",
      "|    ep_rew_mean          | 0.556    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1068     |\n",
      "|    iterations           | 27       |\n",
      "|    time_elapsed         | 413      |\n",
      "|    total_timesteps      | 442368   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.694   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00131  |\n",
      "|    n_updates            | 364      |\n",
      "|    policy_gradient_loss | -2.8e-10 |\n",
      "|    value_loss           | 0.0119   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.4      |\n",
      "|    ep_rew_mean          | 0.892    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1069     |\n",
      "|    iterations           | 28       |\n",
      "|    time_elapsed         | 428      |\n",
      "|    total_timesteps      | 458752   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.877   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00111  |\n",
      "|    n_updates            | 378      |\n",
      "|    policy_gradient_loss | 4.7e-11  |\n",
      "|    value_loss           | 0.0151   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.4       |\n",
      "|    ep_rew_mean          | 0.884     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1071      |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 443       |\n",
      "|    total_timesteps      | 475136    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -1.08     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00139   |\n",
      "|    n_updates            | 392       |\n",
      "|    policy_gradient_loss | -9.67e-11 |\n",
      "|    value_loss           | 0.0111    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.32      |\n",
      "|    ep_rew_mean          | 1.07      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1072      |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 458       |\n",
      "|    total_timesteps      | 491520    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.891    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000486  |\n",
      "|    n_updates            | 406       |\n",
      "|    policy_gradient_loss | -5.98e-10 |\n",
      "|    value_loss           | 0.00941   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.56      |\n",
      "|    ep_rew_mean          | 0.896     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1073      |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 473       |\n",
      "|    total_timesteps      | 507904    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.556    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.000973  |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -5.83e-11 |\n",
      "|    value_loss           | 0.0115    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x7f819b8307c0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imitationEnv = make_vec_env(GridworldImitation, n_envs= 8, env_kwargs={\"lambda1\" : 0})\n",
    "\n",
    "ImitationModel = MaskablePPO(MaskableActorCriticPolicy, imitationEnv, verbose= 1,n_epochs = 14, gamma=1)\n",
    "# train for 14 epochs\n",
    "ImitationModel.learn(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 %\n",
      "20.0 %\n",
      "30.0 %\n",
      "40.0 %\n",
      "50.0 %\n",
      "60.0 %\n",
      "70.0 %\n",
      "80.0 %\n",
      "90.0 %\n",
      "100.0 %\n",
      "correct : 184, accuracy: 1.84 %\n"
     ]
    }
   ],
   "source": [
    "test_RL_models(ImitationModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnv = GridworldForcedFinished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['>' '#' '#' '.']\n",
      "  ['.' 'O' '#' '.']\n",
      "  ['.' '#' '.' '.']\n",
      "  ['.' '.' '#' '.']]\n",
      "\n",
      " [['.' '#' '#' '.']\n",
      "  ['O' 'O' '#' '.']\n",
      "  ['<' '#' '.' '.']\n",
      "  ['.' '.' '#' '.']]]\n"
     ]
    }
   ],
   "source": [
    "test = testEnv.reset()\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0 False\n",
      "[[['^' '#' '#' '.']\n",
      "  ['.' 'O' '#' '.']\n",
      "  ['.' '#' '.' '.']\n",
      "  ['.' '.' '#' '.']]\n",
      "\n",
      " [['.' '#' '#' '.']\n",
      "  ['O' 'O' '#' '.']\n",
      "  ['<' '#' '.' '.']\n",
      "  ['.' '.' '#' '.']]]\n"
     ]
    }
   ],
   "source": [
    "action = ImitationModel.predict(test, action_masks=testEnv.action_masks(), deterministic= True)[0]\n",
    "print(action)\n",
    "test, rew, done, _ = testEnv.step(action)\n",
    "print(rew, done)\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imitation Learning using a Custom Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.Space, features_dim: int = 32):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 8, 3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(8, 32, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = torch.flatten(x, start_dim= 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "net_arch = [\n",
    "    32,16, 8,\n",
    "    dict(vf = [8,4], pi = [8,4])\n",
    "]\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class = CustomFeatureExtractor,\n",
    "    net_arch = net_arch\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5.44     |\n",
      "|    ep_rew_mean     | 0.972    |\n",
      "| time/              |          |\n",
      "|    fps             | 2228     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.04      |\n",
      "|    ep_rew_mean          | 0.884     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1194      |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.97     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0319    |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -1.05e-09 |\n",
      "|    value_loss           | 0.124     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.88      |\n",
      "|    ep_rew_mean          | 0.98      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1025      |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.282    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00683   |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -6.62e-10 |\n",
      "|    value_loss           | 0.112     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.56      |\n",
      "|    ep_rew_mean          | 0.88      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 963       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0         |\n",
      "|    explained_variance   | -0.298    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0438    |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -1.55e-10 |\n",
      "|    value_loss           | 0.108     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.2      |\n",
      "|    ep_rew_mean          | 0.908    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 932      |\n",
      "|    iterations           | 5        |\n",
      "|    time_elapsed         | 43       |\n",
      "|    total_timesteps      | 40960    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.609   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0312   |\n",
      "|    n_updates            | 40       |\n",
      "|    policy_gradient_loss | 2.56e-10 |\n",
      "|    value_loss           | 0.0894   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.04     |\n",
      "|    ep_rew_mean          | 0.88     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 920      |\n",
      "|    iterations           | 6        |\n",
      "|    time_elapsed         | 53       |\n",
      "|    total_timesteps      | 49152    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.486   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00486  |\n",
      "|    n_updates            | 50       |\n",
      "|    policy_gradient_loss | -1.8e-10 |\n",
      "|    value_loss           | 0.111    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.48     |\n",
      "|    ep_rew_mean          | 1.05     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 912      |\n",
      "|    iterations           | 7        |\n",
      "|    time_elapsed         | 62       |\n",
      "|    total_timesteps      | 57344    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.176   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0166   |\n",
      "|    n_updates            | 60       |\n",
      "|    policy_gradient_loss | 2.03e-10 |\n",
      "|    value_loss           | 0.114    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.8      |\n",
      "|    ep_rew_mean          | 1.06     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 902      |\n",
      "|    iterations           | 8        |\n",
      "|    time_elapsed         | 72       |\n",
      "|    total_timesteps      | 65536    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.952   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00431  |\n",
      "|    n_updates            | 70       |\n",
      "|    policy_gradient_loss | 6.96e-10 |\n",
      "|    value_loss           | 0.0799   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.84     |\n",
      "|    ep_rew_mean          | 0.62     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 892      |\n",
      "|    iterations           | 9        |\n",
      "|    time_elapsed         | 82       |\n",
      "|    total_timesteps      | 73728    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.573   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00125  |\n",
      "|    n_updates            | 80       |\n",
      "|    policy_gradient_loss | 5.7e-10  |\n",
      "|    value_loss           | 0.0819   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.16     |\n",
      "|    ep_rew_mean          | 0.984    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 886      |\n",
      "|    iterations           | 10       |\n",
      "|    time_elapsed         | 92       |\n",
      "|    total_timesteps      | 81920    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.574   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00352  |\n",
      "|    n_updates            | 90       |\n",
      "|    policy_gradient_loss | 2.67e-10 |\n",
      "|    value_loss           | 0.156    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 4.8      |\n",
      "|    ep_rew_mean          | 0.892    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 879      |\n",
      "|    iterations           | 11       |\n",
      "|    time_elapsed         | 102      |\n",
      "|    total_timesteps      | 90112    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.245   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.00206  |\n",
      "|    n_updates            | 100      |\n",
      "|    policy_gradient_loss | 4.95e-10 |\n",
      "|    value_loss           | 0.0857   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.12     |\n",
      "|    ep_rew_mean          | 0.884    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 874      |\n",
      "|    iterations           | 12       |\n",
      "|    time_elapsed         | 112      |\n",
      "|    total_timesteps      | 98304    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.583   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.127    |\n",
      "|    n_updates            | 110      |\n",
      "|    policy_gradient_loss | 6.68e-11 |\n",
      "|    value_loss           | 0.19     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 5.04     |\n",
      "|    ep_rew_mean          | 0.9      |\n",
      "| time/                   |          |\n",
      "|    fps                  | 871      |\n",
      "|    iterations           | 13       |\n",
      "|    time_elapsed         | 122      |\n",
      "|    total_timesteps      | 106496   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0        |\n",
      "|    explained_variance   | -0.195   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.179    |\n",
      "|    n_updates            | 120      |\n",
      "|    policy_gradient_loss | 2.04e-10 |\n",
      "|    value_loss           | 0.143    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x7f80e86b3fd0>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imitationEnv =make_vec_env(GridworldImitation, n_envs= 4)\n",
    "\n",
    "ImitationModelCustom = MaskablePPO(MaskableActorCriticPolicy, imitationEnv, policy_kwargs= policy_kwargs, verbose= 1)\n",
    "# train for 14 epochs\n",
    "ImitationModelCustom.learn(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0 %\n",
      "40.0 %\n",
      "60.0 %\n",
      "80.0 %\n",
      "100.0 %\n",
      "correct : 2, accuracy: 0.04 %\n"
     ]
    }
   ],
   "source": [
    "test_RL_models(ImitationModelCustom)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
