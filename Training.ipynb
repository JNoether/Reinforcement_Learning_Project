{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch \n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from MDP import MDP\n",
    "\n",
    "import stable_baselines3\n",
    "import sb3_contrib\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['.' '.' '.' '#']\n",
      "  ['v' '#' '#' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.01\n",
      "[[['.' '.' '.' '#']\n",
      "  ['d' '#' '#' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.1\n",
      "[[['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.01\n",
      "[[['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n"
     ]
    }
   ],
   "source": [
    "#load MDP\n",
    "mdp = MDP(dir = \"data_medium\", type = \"val\", name = \"100595\")\n",
    "# show grid\n",
    "done = False\n",
    "for a in [\"move\", \"putMarker\", \"move\"]:\n",
    "    if done:\n",
    "        break\n",
    "    next, rew, done, b = mdp.sample_next_state_and_reward(a)\n",
    "    mdp.print_grid()\n",
    "    print(rew)\n",
    "mdp.print_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model with Imitation learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seq', 'task']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data tests\n",
    "os.listdir(\"datasets/data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "\n",
    "#numerical representation of actions\n",
    "getNumAction = {\n",
    "    \"move\" : 0,\n",
    "    \"turnRight\": 1,\n",
    "    \"turnLeft\" : 2,\n",
    "    \"pickMarker\": 3,\n",
    "    \"putMarker\" : 4,\n",
    "    \"finish\" : 5\n",
    "}\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    attributes:\n",
    "    dir : str list :=  accepted directories (data, data_easy, data_medium)\n",
    "    type : str list := train and/or val\n",
    "    grid : tensor := a tensor of all available grids\n",
    "    actions : tensor := vector of the optimal action for each\n",
    "    \"\"\"\n",
    "    def data_generator(self):\n",
    "        for dir in self.dir:\n",
    "            for type in self.type:\n",
    "                for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "                    i = re.sub(r\"\\D\", \"\", i)\n",
    "                    # load MDP and optimal sequence\n",
    "                    currMDP = MDP(dir = dir, type = type, name = str(i))\n",
    "\n",
    "                    with open(os.sep.join([\"datasets\", dir, type, \"seq\", str(i) + \"_seq.json\"])) as seq:\n",
    "                        sequence = json.load(seq)[\"sequence\"]\n",
    "                    \n",
    "                    for action in sequence:\n",
    "                        yield currMDP.get_current_state().copy(), action\n",
    "                        currMDP.get_next_state(action)\n",
    "\n",
    "\n",
    "    def __init__(self, dir = [\"data\", \"data_easy\", \"data_medium\"], type = [\"train\"]) -> None:\n",
    "        \"\"\"\n",
    "        dir : str list :=  accepted directories (data, data_easy, data_medium)\n",
    "        type : str list := train and/or val\n",
    "        \"\"\"\n",
    "        self.dir = dir\n",
    "        self.type = type\n",
    "        lstActionsAndGrids = list(self.data_generator())\n",
    "        self.grid = torch.tensor(np.array([x[0] for x in lstActionsAndGrids]) / 10, device= device)\n",
    "        self.actions = torch.tensor(np.array([getNumAction[x[1]] for x in lstActionsAndGrids]), device= device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.grid)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.grid[idx], self.actions[idx]\n",
    "\n",
    "trainDataset = Dataset()\n",
    "valDataset = Dataset(type = [\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Neural Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    input : 2 X 4 X 4 grid\n",
    "    label : Move [0;6]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # first layer: input\n",
    "        self.conv1 = nn.Conv2d(2, 8, 2)\n",
    "\n",
    "        #second layer : 2nd convolution\n",
    "        self.conv2 = nn.Conv2d(8, 16, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 16)\n",
    "\n",
    "        self.out = nn.Linear(16, 6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = self.out(x)\n",
    "    \n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(2, 8, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (out): Linear(in_features=16, out_features=6, bias=True)\n",
      ")\n",
      "number of parameters: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating model\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "print(f\"number of parameters: {len(params)}\")\n",
    "\n",
    "#loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "dataloader = data.DataLoader(trainDataset, BATCH_SIZE)\n",
    "validationLoader = data.DataLoader(valDataset, BATCH_SIZE)\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        lossVal = loss(outputs, labels)\n",
    "        lossVal.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += lossVal.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(dataloader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "  batch 1000 loss: 1.5848046754598617\n",
      "  batch 2000 loss: 1.5772080620527267\n",
      "  batch 3000 loss: 1.5715919814109802\n",
      "  batch 4000 loss: 1.570342153787613\n",
      "  batch 5000 loss: 1.472266589641571\n",
      "  batch 6000 loss: 1.361961393892765\n",
      "  batch 7000 loss: 1.2709462715387345\n",
      "  batch 8000 loss: 0.9783029281198978\n",
      "  batch 9000 loss: 1.169719327032566\n",
      "  batch 10000 loss: 1.15325086414814\n",
      "Loss train 1.15325086414814 validation 1.1036205291748047\n",
      "EPOCH 2\n",
      "  batch 1000 loss: 1.1210624485611915\n",
      "  batch 2000 loss: 1.0930512836575508\n",
      "  batch 3000 loss: 1.0643902769088744\n",
      "  batch 4000 loss: 1.063572628557682\n",
      "  batch 5000 loss: 1.0348783017992973\n",
      "  batch 6000 loss: 1.0234251257181168\n",
      "  batch 7000 loss: 1.002744925737381\n",
      "  batch 8000 loss: 0.7666354396194219\n",
      "  batch 9000 loss: 0.9100256303399801\n",
      "  batch 10000 loss: 0.8938006875514984\n",
      "Loss train 0.8938006875514984 validation 0.9398242235183716\n",
      "EPOCH 3\n",
      "  batch 1000 loss: 0.9666195095181466\n",
      "  batch 2000 loss: 0.943132805198431\n",
      "  batch 3000 loss: 0.932166943192482\n",
      "  batch 4000 loss: 0.9401529870927334\n",
      "  batch 5000 loss: 0.9203544070422649\n",
      "  batch 6000 loss: 0.9047875367105007\n",
      "  batch 7000 loss: 0.8976959220170975\n",
      "  batch 8000 loss: 0.6870635501146316\n",
      "  batch 9000 loss: 0.7588882497251034\n",
      "  batch 10000 loss: 0.736291059076786\n",
      "Loss train 0.736291059076786 validation 0.8422553539276123\n",
      "EPOCH 4\n",
      "  batch 1000 loss: 0.8867198038101196\n",
      "  batch 2000 loss: 0.8542912537157535\n",
      "  batch 3000 loss: 0.838361478626728\n",
      "  batch 4000 loss: 0.8444905425310135\n",
      "  batch 5000 loss: 0.8367392613887786\n",
      "  batch 6000 loss: 0.8248691573441028\n",
      "  batch 7000 loss: 0.8191811257004737\n",
      "  batch 8000 loss: 0.6201407213434577\n",
      "  batch 9000 loss: 0.6670920702889561\n",
      "  batch 10000 loss: 0.6365541193187236\n",
      "Loss train 0.6365541193187236 validation 0.8447287678718567\n",
      "EPOCH 5\n",
      "  batch 1000 loss: 0.83141602024436\n",
      "  batch 2000 loss: 0.8044891560375691\n",
      "  batch 3000 loss: 0.8017503882050514\n",
      "  batch 4000 loss: 0.7959251726269722\n",
      "  batch 5000 loss: 0.793781172990799\n",
      "  batch 6000 loss: 0.7823648951351643\n",
      "  batch 7000 loss: 0.7753837157934904\n",
      "  batch 8000 loss: 0.5764211186021566\n",
      "  batch 9000 loss: 0.6027089493498207\n",
      "  batch 10000 loss: 0.5862770196050405\n",
      "Loss train 0.5862770196050405 validation 0.7882387638092041\n",
      "EPOCH 6\n",
      "  batch 1000 loss: 0.7947659642994404\n",
      "  batch 2000 loss: 0.771097106218338\n",
      "  batch 3000 loss: 0.7571441144049168\n",
      "  batch 4000 loss: 0.7604697745591402\n",
      "  batch 5000 loss: 0.7558834720999003\n",
      "  batch 6000 loss: 0.7418366447687149\n",
      "  batch 7000 loss: 0.7363420980125666\n",
      "  batch 8000 loss: 0.531639567002654\n",
      "  batch 9000 loss: 0.5615303472429514\n",
      "  batch 10000 loss: 0.5350267981030047\n",
      "Loss train 0.5350267981030047 validation 0.7783156037330627\n",
      "EPOCH 7\n",
      "  batch 1000 loss: 0.7679008899331092\n",
      "  batch 2000 loss: 0.7350112796127796\n",
      "  batch 3000 loss: 0.7279067615866661\n",
      "  batch 4000 loss: 0.7294397350698709\n",
      "  batch 5000 loss: 0.7159464571177959\n",
      "  batch 6000 loss: 0.7155964643061161\n",
      "  batch 7000 loss: 0.7069873354732991\n",
      "  batch 8000 loss: 0.506773322109133\n",
      "  batch 9000 loss: 0.5138858001567423\n",
      "  batch 10000 loss: 0.5023692549094558\n",
      "Loss train 0.5023692549094558 validation 0.7227255702018738\n",
      "EPOCH 8\n",
      "  batch 1000 loss: 0.7494382465183735\n",
      "  batch 2000 loss: 0.7056468580514192\n",
      "  batch 3000 loss: 0.7044480049163103\n",
      "  batch 4000 loss: 0.7023514380455017\n",
      "  batch 5000 loss: 0.6889430927634239\n",
      "  batch 6000 loss: 0.6934668641984463\n",
      "  batch 7000 loss: 0.6707313002124429\n",
      "  batch 8000 loss: 0.4761698370538652\n",
      "  batch 9000 loss: 0.47923319636657835\n",
      "  batch 10000 loss: 0.46533741598576306\n",
      "Loss train 0.46533741598576306 validation 0.698108434677124\n",
      "EPOCH 9\n",
      "  batch 1000 loss: 0.7254463104754686\n",
      "  batch 2000 loss: 0.68845637370646\n",
      "  batch 3000 loss: 0.6776876084804535\n",
      "  batch 4000 loss: 0.6864021070599556\n",
      "  batch 5000 loss: 0.6660325974225998\n",
      "  batch 6000 loss: 0.672372713342309\n",
      "  batch 7000 loss: 0.6589401698559523\n",
      "  batch 8000 loss: 0.45212441105023027\n",
      "  batch 9000 loss: 0.4619118278995156\n",
      "  batch 10000 loss: 0.4335351582467556\n",
      "Loss train 0.4335351582467556 validation 0.6563202738761902\n",
      "EPOCH 10\n",
      "  batch 1000 loss: 0.7046389763206243\n",
      "  batch 2000 loss: 0.6702945037782192\n",
      "  batch 3000 loss: 0.6615028134286404\n",
      "  batch 4000 loss: 0.6583534435778856\n",
      "  batch 5000 loss: 0.6610807644426823\n",
      "  batch 6000 loss: 0.6527225747853518\n",
      "  batch 7000 loss: 0.6478557813540101\n",
      "  batch 8000 loss: 0.43125885124318303\n",
      "  batch 9000 loss: 0.432843007452786\n",
      "  batch 10000 loss: 0.4208894909694791\n",
      "Loss train 0.4208894909694791 validation 0.6390317678451538\n",
      "EPOCH 11\n",
      "  batch 1000 loss: 0.682734268695116\n",
      "  batch 2000 loss: 0.6614417805969716\n",
      "  batch 3000 loss: 0.6499329867810011\n",
      "  batch 4000 loss: 0.6422392347157001\n",
      "  batch 5000 loss: 0.6356414394676685\n",
      "  batch 6000 loss: 0.64194346781075\n",
      "  batch 7000 loss: 0.6294929992258549\n",
      "  batch 8000 loss: 0.4186709449198097\n",
      "  batch 9000 loss: 0.4237182648796588\n",
      "  batch 10000 loss: 0.4082521043680608\n",
      "Loss train 0.4082521043680608 validation 0.6176177859306335\n",
      "EPOCH 12\n",
      "  batch 1000 loss: 0.6872143642604351\n",
      "  batch 2000 loss: 0.6573526435941458\n",
      "  batch 3000 loss: 0.6356478052586317\n",
      "  batch 4000 loss: 0.6268183221518994\n",
      "  batch 5000 loss: 0.6244157951176167\n",
      "  batch 6000 loss: 0.634989134401083\n",
      "  batch 7000 loss: 0.6258083952516318\n",
      "  batch 8000 loss: 0.39994210229627786\n",
      "  batch 9000 loss: 0.40444297915510835\n",
      "  batch 10000 loss: 0.4005714733786881\n",
      "Loss train 0.4005714733786881 validation 0.611839771270752\n",
      "EPOCH 13\n",
      "  batch 1000 loss: 0.6699195929765701\n",
      "  batch 2000 loss: 0.6327724977433682\n",
      "  batch 3000 loss: 0.6330101857483387\n",
      "  batch 4000 loss: 0.6181697361767292\n",
      "  batch 5000 loss: 0.608877857297659\n",
      "  batch 6000 loss: 0.6235277875959874\n",
      "  batch 7000 loss: 0.6148639786168932\n",
      "  batch 8000 loss: 0.39434234702028337\n",
      "  batch 9000 loss: 0.3853021551892161\n",
      "  batch 10000 loss: 0.38773934199661014\n",
      "Loss train 0.38773934199661014 validation 0.6038804650306702\n",
      "EPOCH 14\n",
      "  batch 1000 loss: 0.6533131606727839\n",
      "  batch 2000 loss: 0.617745683953166\n",
      "  batch 3000 loss: 0.6298281653523445\n",
      "  batch 4000 loss: 0.6063167158961296\n",
      "  batch 5000 loss: 0.598906685769558\n",
      "  batch 6000 loss: 0.6139930442422629\n",
      "  batch 7000 loss: 0.5987186649218201\n",
      "  batch 8000 loss: 0.37427560377772895\n",
      "  batch 9000 loss: 0.37452496081218123\n",
      "  batch 10000 loss: 0.39385036879219115\n",
      "Loss train 0.39385036879219115 validation 0.588007926940918\n",
      "EPOCH 15\n",
      "  batch 1000 loss: 0.6371824314668775\n",
      "  batch 2000 loss: 0.6074377992153168\n",
      "  batch 3000 loss: 0.6061624436527491\n",
      "  batch 4000 loss: 0.5943748523071408\n",
      "  batch 5000 loss: 0.5908321985453368\n",
      "  batch 6000 loss: 0.5995710975974798\n",
      "  batch 7000 loss: 0.5921617800816894\n",
      "  batch 8000 loss: 0.36339820172078907\n",
      "  batch 9000 loss: 0.37626211550459265\n",
      "  batch 10000 loss: 0.3657472871728241\n",
      "Loss train 0.3657472871728241 validation 0.5800681710243225\n",
      "EPOCH 16\n",
      "  batch 1000 loss: 0.6318387076482177\n",
      "  batch 2000 loss: 0.5939548528045416\n",
      "  batch 3000 loss: 0.596889304175973\n",
      "  batch 4000 loss: 0.5883691572546959\n",
      "  batch 5000 loss: 0.5813523345366121\n",
      "  batch 6000 loss: 0.6038870230317116\n",
      "  batch 7000 loss: 0.5734757657945156\n",
      "  batch 8000 loss: 0.3544666825048626\n",
      "  batch 9000 loss: 0.35929238827899096\n",
      "  batch 10000 loss: 0.3566026320457458\n",
      "Loss train 0.3566026320457458 validation 0.585335373878479\n",
      "EPOCH 17\n",
      "  batch 1000 loss: 0.626651862770319\n",
      "  batch 2000 loss: 0.5817846498191357\n",
      "  batch 3000 loss: 0.5852808546870947\n",
      "  batch 4000 loss: 0.5724683390408755\n",
      "  batch 5000 loss: 0.5759867084845901\n",
      "  batch 6000 loss: 0.5836609973907471\n",
      "  batch 7000 loss: 0.5668464862927795\n",
      "  batch 8000 loss: 0.34491028706356885\n",
      "  batch 9000 loss: 0.34674230801686645\n",
      "  batch 10000 loss: 0.3603722093394026\n",
      "Loss train 0.3603722093394026 validation 0.5582578182220459\n",
      "EPOCH 18\n",
      "  batch 1000 loss: 0.6180783730372786\n",
      "  batch 2000 loss: 0.5697758455127477\n",
      "  batch 3000 loss: 0.5785850515887141\n",
      "  batch 4000 loss: 0.5740112640336156\n",
      "  batch 5000 loss: 0.5567379411309957\n",
      "  batch 6000 loss: 0.5706410413831472\n",
      "  batch 7000 loss: 0.5636598347201943\n",
      "  batch 8000 loss: 0.3388310892963782\n",
      "  batch 9000 loss: 0.33997725232318043\n",
      "  batch 10000 loss: 0.34173691944312307\n",
      "Loss train 0.34173691944312307 validation 0.5667731165885925\n",
      "EPOCH 19\n",
      "  batch 1000 loss: 0.6056515919268132\n",
      "  batch 2000 loss: 0.5684202916622162\n",
      "  batch 3000 loss: 0.5725924377441406\n",
      "  batch 4000 loss: 0.5646463255882264\n",
      "  batch 5000 loss: 0.5594606110304594\n",
      "  batch 6000 loss: 0.5680521754920482\n",
      "  batch 7000 loss: 0.5551865320950746\n",
      "  batch 8000 loss: 0.3295054679615423\n",
      "  batch 9000 loss: 0.3345037630777806\n",
      "  batch 10000 loss: 0.3421134553104639\n",
      "Loss train 0.3421134553104639 validation 0.5554923415184021\n",
      "EPOCH 20\n",
      "  batch 1000 loss: 0.5935746854022145\n",
      "  batch 2000 loss: 0.5632749598026275\n",
      "  batch 3000 loss: 0.5632396476715803\n",
      "  batch 4000 loss: 0.5923111943230033\n",
      "  batch 5000 loss: 0.5467019193023444\n",
      "  batch 6000 loss: 0.5586824364662171\n",
      "  batch 7000 loss: 0.5623804821670055\n",
      "  batch 8000 loss: 0.3229494813526981\n",
      "  batch 9000 loss: 0.3279202521760017\n",
      "  batch 10000 loss: 0.34377561761252584\n",
      "Loss train 0.34377561761252584 validation 0.5518881678581238\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "writer = SummaryWriter(\"runs/imitation_learning_{}\".format(timestamp))\n",
    "epoch_num = 0\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "EPOCHS = 14\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH {}\".format(epoch_num + 1))\n",
    "\n",
    "    net.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_num, writer)\n",
    "\n",
    "    net.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(validationLoader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vout = net(vinputs)\n",
    "        vloss = loss(vout, vlabels)\n",
    "        running_vloss += vloss\n",
    "    avg_vloss = running_vloss / (i+1)\n",
    "    print(f\"Loss train {avg_loss} validation {avg_vloss}\")\n",
    "\n",
    "\n",
    "    writer.add_scalars(\"Training Loss\", {\"Training\" : avg_loss, \"validation\" : avg_vloss})\n",
    "    writer.flush()\n",
    "\n",
    "    epoch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['>' '.' '.' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.01\n",
      "[[['.' '>' '.' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.015\n",
      "[[['.' '.' '>' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.017499999999999998\n",
      "[[['.' '.' '.' 'r']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: turnLeft, reward: 0.017499999999999998\n",
      "[[['.' '.' '.' 'u']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.045, 5, False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "actions = [\"move\", \"turnRight\", \"turnLeft\", \"pickMarker\", \"putMarker\", \"finish\"]\n",
    "\n",
    "testMDP = MDP(dir = \"data\", type = \"val\", name = \"100112\")\n",
    "\n",
    "def apply_to_grid(MDP, show_grid):\n",
    "    reward = 0\n",
    "    steps = 0\n",
    "    if show_grid:\n",
    "        MDP.print_grid()\n",
    "    while True:\n",
    "        current_grid = torch.tensor(MDP.get_current_state(), device= device) / 10\n",
    "        out = net(current_grid.unsqueeze(0))\n",
    "        nextAction = actions[torch.argmax(out)]\n",
    "        reward += MDP.gamma**steps * MDP.reward(nextAction)\n",
    "        steps += 1\n",
    "        if MDP.get_next_state(nextAction) == \"Terminal\" or steps > 100:\n",
    "            return reward, steps, MDP.task_solved()\n",
    "        if show_grid:\n",
    "            print(\"action: {}, reward: {}\".format(nextAction, reward))\n",
    "            MDP.print_grid()\n",
    "\n",
    "\n",
    "apply_to_grid(testMDP, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks solved with only imitation learning:\n",
      "Total : 2475, accuracy: 0.1436448055716773\n"
     ]
    }
   ],
   "source": [
    "# check accuracy of solved tasks\n",
    "sucesses = 0\n",
    "for dir in [\"data\", \"data_easy\", \"data_medium\"]:\n",
    "    for type in [\"val\"]:\n",
    "        for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "            i = re.sub(r\"\\D\", \"\", i)\n",
    "            curr_MDP = MDP(dir, type, i)\n",
    "            if apply_to_grid(curr_MDP, False)[-1]:\n",
    "                sucesses += 1\n",
    "\n",
    "print(\"tasks solved with only imitation learning:\")\n",
    "print(f\"Total : {sucesses}, accuracy: {sucesses / len(valDataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clearly seen here, imitation learning with the limited amount of training data is not able to solve most of the provided tasks. Therefore, in the following I will use the described PPO approach and after that will create the final model that uses imitation learning to initiate the model and then trains it with maskless PPO to achieve the best possible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['<' '#' '#' '.']\n",
      "  ['#' '.' '#' '#']\n",
      "  ['#' '#' '#' '#']\n",
      "  ['#' '#' '.' '#']]\n",
      "\n",
      " [['<' '#' '#' '.']\n",
      "  ['#' '.' '#' '#']\n",
      "  ['#' '#' '#' '#']\n",
      "  ['#' '#' '.' '#']]]\n"
     ]
    }
   ],
   "source": [
    "# test generated MDPs\n",
    "test = np.random.randint(1, 1e5)\n",
    "\n",
    "genMDP = MDP(\"generated\", \"train\", str(test))\n",
    "\n",
    "genMDP.print_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom environment\n",
    "from gym import spaces\n",
    "\n",
    "class Gridworld(gym.Env):\n",
    "\n",
    "    metadata = {\"render.modes\" : [\"human\"]}\n",
    "\n",
    "    def MDP_generator(self):\n",
    "        while True:\n",
    "            for dir in self.dir:\n",
    "                for type in self.type:\n",
    "                    for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "                        i = re.sub(r\"\\D\", \"\", i)\n",
    "                        yield dir, type, i\n",
    "\n",
    "    def __init__(self, dir = [\"data\", \"data_easy\", \"data_medium\"], type = [\"train\"], lambda1 = 0.01, lambda2 = 0.1, lambda3 = 1) -> None:\n",
    "        super(Gridworld, self).__init__()\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(low = 0, high = 10, shape = (2, 4, 4))\n",
    "\n",
    "        #available MDPs\n",
    "        self.dir = dir\n",
    "        self.type = type\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.lambda3 = lambda3\n",
    "\n",
    "\n",
    "\n",
    "        self.next_MDP = self.MDP_generator()\n",
    "        self.actions = [\"move\", \"turnLeft\", \"turnRight\", \"pickMarker\", \"putMarker\", \"finish\"]\n",
    "\n",
    "    def reset(self):\n",
    "        nextDir, nextType, nexti =  next(self.next_MDP)\n",
    "        self.currentMDP = MDP(nextDir, nextType, nexti, lambda1= self.lambda1, lambda2 = self.lambda2, lambda3 =self.lambda3)\n",
    "        return self.currentMDP.get_current_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.currentMDP.sample_next_state_and_reward(self.actions[action])\n",
    "        \n",
    "    def render(self):\n",
    "        self.currentMDP.print_grid()\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def action_masks(self):\n",
    "        return self.currentMDP.action_mask()\n",
    "\n",
    "    def get_MDP(self):\n",
    "        return self.currentMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "testEnv = Gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53     |\n",
      "|    ep_rew_mean     | -0.384   |\n",
      "| time/              |          |\n",
      "|    fps             | 4664     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.84        |\n",
      "|    ep_rew_mean          | -0.272      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2487        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.067049526 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -1.52       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00382    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0547     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.31        |\n",
      "|    ep_rew_mean          | -0.154      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2120        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032305546 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -0.332      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0537     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.87        |\n",
      "|    ep_rew_mean          | -0.119      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2001        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024943938 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -0.394      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0276     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0449     |\n",
      "|    value_loss           | 0.0574      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76        |\n",
      "|    ep_rew_mean          | -0.088      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1933        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018737532 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.71       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00803    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69        |\n",
      "|    ep_rew_mean          | -0.075      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1882        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014659116 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.872      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0709     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0347     |\n",
      "|    value_loss           | 0.0117      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.98        |\n",
      "|    ep_rew_mean          | -0.046      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1854        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017766759 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.891      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    value_loss           | 0.00771     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54        |\n",
      "|    ep_rew_mean          | -0.048      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1832        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019406248 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.926      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0396     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    value_loss           | 0.00434     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.92        |\n",
      "|    ep_rew_mean          | -0.032      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1811        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025775779 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -0.401      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0575     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0528     |\n",
      "|    value_loss           | 0.00347     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.85        |\n",
      "|    ep_rew_mean          | -0.017      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1795        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025487471 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | -0.262      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0884     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.05       |\n",
      "|    value_loss           | 0.00328     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81        |\n",
      "|    ep_rew_mean          | -0.014      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1781        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023201171 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | -0.251      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.07       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    value_loss           | 0.00249     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.94        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1771        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018107843 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.72       |\n",
      "|    explained_variance   | -0.128      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0335     |\n",
      "|    value_loss           | 0.00202     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.92        |\n",
      "|    ep_rew_mean          | -0.004      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1769        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012312788 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | -0.165      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00126    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.00142     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81        |\n",
      "|    ep_rew_mean          | -0.003      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1767        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012321491 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | -0.587      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.000424    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41        |\n",
      "|    ep_rew_mean          | -0.002      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1763        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009046601 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.000782    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.95        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1752        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011041418 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.54       |\n",
      "|    explained_variance   | -0.457      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.000165    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.03        |\n",
      "|    ep_rew_mean          | -0.002      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1739        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010586654 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | -0.244      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000892    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000209    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.98        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1728        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012334334 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | -0.368      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00752     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 6.19e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.2         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1725        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012339989 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | -0.0909     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.000179    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.93        |\n",
      "|    ep_rew_mean          | -0.001      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1718        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010442607 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.604      |\n",
      "|    explained_variance   | -0.338      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 3.39e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.34        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1716        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015234548 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | -0.112      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0441     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 3.24e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.6         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1713        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018277075 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | -0.205      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0339     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 2.62e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.83        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1711        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013504181 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | -0.355      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0321     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 1.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.2         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018164074 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | -1.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 4.68e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.53        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014087643 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | -0.137      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0333     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 5.92e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.76        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016080918 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.689      |\n",
      "|    explained_variance   | -0.484      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0554     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 4.95e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.63        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1708        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011534102 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.689      |\n",
      "|    explained_variance   | -8.85e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.00864     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.27        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1707        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012842584 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | -0.0358     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0268      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.00819     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.58         |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1705         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123186335 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.683       |\n",
      "|    explained_variance   | -0.138       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0477      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    value_loss           | 0.00312      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.56        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1704        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014000794 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.672      |\n",
      "|    explained_variance   | -1.23       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0072     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.00061     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.25        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1702        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196265 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | -0.0843     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0339     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.00129     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.43        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1700        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013138529 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | -0.336      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00246     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.00107     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.24        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1701        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012056604 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | -0.0864     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    value_loss           | 0.00152     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.71       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1700       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01688756 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.71      |\n",
      "|    explained_variance   | -11.8      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0295    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 2.2e-05    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.64        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012747726 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | -5.4        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0223     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 1.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.44        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011837827 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | -0.0286     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.031      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.000507    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.9         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1697        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012203876 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | -0.0251     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    value_loss           | 0.000732    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.48       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1698       |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01744307 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.741     |\n",
      "|    explained_variance   | -0.267     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00936   |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    value_loss           | 0.000613   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.2         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013428509 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | -5.91       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 1.98e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.7         |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012138868 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | -0.0312     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    value_loss           | 0.000783    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.21       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1699       |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 335872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01855794 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.697     |\n",
      "|    explained_variance   | -4.98      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0134    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    value_loss           | 1.79e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.01        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016865842 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.712      |\n",
      "|    explained_variance   | -9.78       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 2.91e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.46        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013537653 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | -0.0212     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00747     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 3.01e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.98        |\n",
      "|    ep_rew_mean          | -0.011      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023850935 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | -8.7        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0354     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 1.54e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.37        |\n",
      "|    ep_rew_mean          | -0.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010772362 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | -0.00115    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 0.00489     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.01        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013096693 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | -0.146      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.0035      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.34        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016081229 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | -1.08       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0194      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000464    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.19       |\n",
      "|    ep_rew_mean          | -0.001     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1699       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 231        |\n",
      "|    total_timesteps      | 393216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01088498 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.606     |\n",
      "|    explained_variance   | 0.0258     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.041     |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00869   |\n",
      "|    value_loss           | 0.00246    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.26       |\n",
      "|    ep_rew_mean          | -0.001     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1699       |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 236        |\n",
      "|    total_timesteps      | 401408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01326372 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.631     |\n",
      "|    explained_variance   | -0.171     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0267    |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    value_loss           | 0.000978   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.95        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1699        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014413526 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | -0.304      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.032      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.000171    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.46        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012520941 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | -0.0083     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.00126     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.34        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1698        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011596083 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | -11.5       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00918     |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    value_loss           | 3.88e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.65        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1697        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015978072 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.614      |\n",
      "|    explained_variance   | -1.64       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00839     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    value_loss           | 4.13e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.44        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1697        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011448194 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | -3.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0145     |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 5.98e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.73        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1696        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013229883 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.563      |\n",
      "|    explained_variance   | -0.783      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00273    |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    value_loss           | 1.65e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.87        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1696        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009509501 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | -0.742      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 1.62e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.88        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1695        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013198145 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | -0.0517     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00331     |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    value_loss           | 2.34e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.14        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1695        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 280         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014449965 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.508      |\n",
      "|    explained_variance   | -0.0339     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.36       |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1695       |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 483328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01750058 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.585     |\n",
      "|    explained_variance   | -0.00424   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0264    |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 0.000684   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.15        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1695        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025704125 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | -1.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00988    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.73e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.27        |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1695        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011511356 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | -0.401      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00334     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 2.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.65        |\n",
      "|    ep_rew_mean          | -0.001      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1694        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018516967 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.578      |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00988    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 3.08e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f3f2d341d00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_vec_env(Gridworld, n_envs= 4, env_kwargs={\"lambda1\" : 0})\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose = 1, gamma= 1)\n",
    "model.learn(5 * 1e5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['.' '^' '.' '.']\n",
      "  ['.' '#' '.' '#']]\n",
      "\n",
      " [['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['v' '.' '.' '.']\n",
      "  ['.' '#' '.' '#']]]\n"
     ]
    }
   ],
   "source": [
    "test = testEnv.reset()\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0 False\n",
      "[[['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['.' '>' '.' '.']\n",
      "  ['.' '#' '.' '#']]\n",
      "\n",
      " [['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['v' '.' '.' '.']\n",
      "  ['.' '#' '.' '#']]]\n"
     ]
    }
   ],
   "source": [
    "action = model.predict(test, deterministic= True)[0]\n",
    "print(action)\n",
    "test, rew, done, _ = testEnv.step(action)\n",
    "print(rew, done)\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_RL_models(model):\n",
    "    valDataset = Gridworld(type = [\"val\"])\n",
    "    correct, total = 0,1e4\n",
    "    for task in range(int(total)):\n",
    "        if task % 1000 == 999:\n",
    "            print(f\"{task+1 / total} %\")\n",
    "        currMDP = valDataset.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = model.predict(currMDP)[0]\n",
    "            if action == 5 and np.array_equal(currMDP[0], currMDP[1]): \n",
    "                correct += 1\n",
    "            currMDP, rew, done, _ = valDataset.step(action)\n",
    "            \n",
    "            \n",
    "    print(f\"correct : {correct}, accuracy: {correct*100/total } %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999.0001 %\n",
      "1999.0001 %\n",
      "2999.0001 %\n",
      "3999.0001 %\n",
      "4999.0001 %\n",
      "5999.0001 %\n",
      "6999.0001 %\n",
      "7999.0001 %\n",
      "8999.0001 %\n",
      "9999.0001 %\n",
      "correct : 0, accuracy: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "test_RL_models(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal PPO model performs even worse then the Imitation learning model. This could be improved with some tuning, but I instead will focus on the maskable PPO model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maskable PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.9     |\n",
      "|    ep_rew_mean     | -0.161   |\n",
      "| time/              |          |\n",
      "|    fps             | 5394     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.3        |\n",
      "|    ep_rew_mean          | -0.181      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2414        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012206229 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -2.36       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00401    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0364      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.7        |\n",
      "|    ep_rew_mean          | -0.189      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2045        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011662807 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.856      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0238     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.0233      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.6        |\n",
      "|    ep_rew_mean          | -0.133      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1893        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012467567 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.172      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.0253      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | -0.0993     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1817        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012883643 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.00597     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00633    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.024       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | 0.0311      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1775        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013237604 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.0358      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.0279      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0547      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1744        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013382076 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00838    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.0313      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x7fb7f991a9a0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskEnv = make_vec_env(Gridworld, n_envs = 8)\n",
    "\n",
    "modelMask = MaskablePPO(MaskableActorCriticPolicy, maskEnv, verbose = 1, gamma = 1)\n",
    "modelMask.learn(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEnv = Gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' '.' '.' '#']\n",
      "  ['#' '.' '#' '.']\n",
      "  ['.' '^' 'O' '.']\n",
      "  ['.' '.' '#' '.']]\n",
      "\n",
      " [['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]]\n"
     ]
    }
   ],
   "source": [
    "test = testEnv.reset()\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1 True\n",
      "[[['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]\n",
      "\n",
      " [['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]]\n"
     ]
    }
   ],
   "source": [
    "action = modelMask.predict(test, action_masks=testEnv.action_masks(), deterministic= True)[0]\n",
    "print(action)\n",
    "test, rew, done, _ = testEnv.step(action)\n",
    "print(rew, done)\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999.0001 %\n",
      "1999.0001 %\n",
      "2999.0001 %\n",
      "3999.0001 %\n",
      "4999.0001 %\n",
      "5999.0001 %\n",
      "6999.0001 %\n",
      "7999.0001 %\n",
      "8999.0001 %\n",
      "9999.0001 %\n",
      "correct : 13, accuracy: 0.13 %\n"
     ]
    }
   ],
   "source": [
    "test_RL_models(modelMask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally I will try using a action mask that forces the agent to use the finish command if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridworldForcedFinished(Gridworld):\n",
    "    def __init__(self, dir=[\"data\", \"data_easy\", \"data_medium\"], type=[\"train\"], lambda1=0.01, lambda2=0.1, lambda3=1) -> None:\n",
    "        super().__init__(dir, type, lambda1, lambda2, lambda3)\n",
    "\n",
    "    def action_masks(self):\n",
    "        mat = super().get_MDP().get_current_state()\n",
    "        if np.array_equal(mat[0], mat[1]):\n",
    "            return np.array([0,0,0,0,0,1])\n",
    "\n",
    "        return super().action_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]\n",
      "\n",
      " [['#' '.' '.' '#']\n",
      "  ['#' '^' '#' '.']\n",
      "  ['.' '.' 'O' '.']\n",
      "  ['.' '.' '#' '.']]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testEnv = GridworldForcedFinished()\n",
    "testEnv.reset()\n",
    "testEnv.step(0)\n",
    "testEnv.render()\n",
    "testEnv.action_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10.9     |\n",
      "|    ep_rew_mean     | -0.078   |\n",
      "| time/              |          |\n",
      "|    fps             | 5389     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.1        |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2311        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013376947 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -1.41       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00956     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.0558      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24          |\n",
      "|    ep_rew_mean          | -0.084      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1973        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013308311 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.26       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00347    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 0.0387      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | 0.013       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1862        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011413913 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.0311      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00659    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.0329      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.3        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1799        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013347257 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.0722      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0225     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.0335      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 54          |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1753        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013437012 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00406    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.0309      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 90.6        |\n",
      "|    ep_rew_mean          | 0.347       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1724        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012764791 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0146     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0274      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sb3_contrib.ppo_mask.ppo_mask.MaskablePPO at 0x7fb7d4867f10>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envForcedFinish = make_vec_env(GridworldForcedFinished, n_envs=8, env_kwargs={\"lambda1\" : 0})\n",
    "\n",
    "modelForcedFinish = MaskablePPO(MaskableActorCriticPolicy, envForcedFinish, verbose= 1, gamma= 1)\n",
    "modelForcedFinish.learn(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['.' '^' '.' '.']\n",
      "  ['.' '#' '.' '#']]\n",
      "\n",
      " [['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['v' '.' '.' '.']\n",
      "  ['.' '#' '.' '#']]]\n"
     ]
    }
   ],
   "source": [
    "test = testEnv.reset()\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0 False\n",
      "[[['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['.' '<' '.' '.']\n",
      "  ['.' '#' '.' '#']]\n",
      "\n",
      " [['#' '.' '.' '.']\n",
      "  ['.' '.' '#' '.']\n",
      "  ['v' '.' '.' '.']\n",
      "  ['.' '#' '.' '#']]]\n"
     ]
    }
   ],
   "source": [
    "action = modelForcedFinish.predict(test, action_masks=testEnv.action_masks(), deterministic= True)[0]\n",
    "print(action)\n",
    "test, rew, done, _ = testEnv.step(action)\n",
    "print(rew, done)\n",
    "testEnv.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999.0001 %\n",
      "1999.0001 %\n",
      "2999.0001 %\n",
      "3999.0001 %\n",
      "4999.0001 %\n",
      "5999.0001 %\n",
      "6999.0001 %\n",
      "7999.0001 %\n",
      "8999.0001 %\n",
      "9999.0001 %\n",
      "correct : 35, accuracy: 0.35 %\n"
     ]
    }
   ],
   "source": [
    "test_RL_models(modelForcedFinish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy did improve, but it is still far from perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize with imitation learning"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
