{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch \n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from MDP import MDP\n",
    "\n",
    "import stable_baselines3\n",
    "import sb3_contrib\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3080'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['.' '.' '.' '#']\n",
      "  ['v' '#' '#' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.01\n",
      "[[['.' '.' '.' '#']\n",
      "  ['d' '#' '#' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.1\n",
      "[[['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n",
      "0.01\n",
      "[[['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '#']\n",
      "  ['O' '#' '#' '#']\n",
      "  ['v' '#' '.' '#']\n",
      "  ['#' '#' '#' '#']]]\n"
     ]
    }
   ],
   "source": [
    "#load MDP\n",
    "mdp = MDP(dir = \"data_medium\", type = \"val\", name = \"100595\")\n",
    "# show grid\n",
    "done = False\n",
    "for a in [\"move\", \"putMarker\", \"move\"]:\n",
    "    if done:\n",
    "        break\n",
    "    next, rew, done, b = mdp.sample_next_state_and_reward(a)\n",
    "    mdp.print_grid()\n",
    "    print(rew)\n",
    "mdp.print_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model with Imitation learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seq', 'task']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data tests\n",
    "os.listdir(\"datasets/data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "\n",
    "#numerical representation of actions\n",
    "getNumAction = {\n",
    "    \"move\" : 0,\n",
    "    \"turnRight\": 1,\n",
    "    \"turnLeft\" : 2,\n",
    "    \"pickMarker\": 3,\n",
    "    \"putMarker\" : 4,\n",
    "    \"finish\" : 5\n",
    "}\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    attributes:\n",
    "    dir : str list :=  accepted directories (data, data_easy, data_medium)\n",
    "    type : str list := train and/or val\n",
    "    grid : tensor := a tensor of all available grids\n",
    "    actions : tensor := vector of the optimal action for each\n",
    "    \"\"\"\n",
    "    def data_generator(self):\n",
    "        for dir in self.dir:\n",
    "            for type in self.type:\n",
    "                for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "                    i = re.sub(r\"\\D\", \"\", i)\n",
    "                    # load MDP and optimal sequence\n",
    "                    currMDP = MDP(dir = dir, type = type, name = str(i))\n",
    "\n",
    "                    with open(os.sep.join([\"datasets\", dir, type, \"seq\", str(i) + \"_seq.json\"])) as seq:\n",
    "                        sequence = json.load(seq)[\"sequence\"]\n",
    "                    \n",
    "                    for action in sequence:\n",
    "                        yield currMDP.get_current_state().copy(), action\n",
    "                        currMDP.get_next_state(action)\n",
    "\n",
    "\n",
    "    def __init__(self, dir = [\"data\", \"data_easy\", \"data_medium\"], type = [\"train\"]) -> None:\n",
    "        \"\"\"\n",
    "        dir : str list :=  accepted directories (data, data_easy, data_medium)\n",
    "        type : str list := train and/or val\n",
    "        \"\"\"\n",
    "        self.dir = dir\n",
    "        self.type = type\n",
    "        lstActionsAndGrids = list(self.data_generator())\n",
    "        self.grid = torch.tensor(np.array([x[0] for x in lstActionsAndGrids]) / 10, device= device)\n",
    "        self.actions = torch.tensor(np.array([getNumAction[x[1]] for x in lstActionsAndGrids]), device= device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.grid)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.grid[idx], self.actions[idx]\n",
    "\n",
    "trainDataset = Dataset()\n",
    "valDataset = Dataset(type = [\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Neural Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    input : 2 X 4 X 4 grid\n",
    "    label : Move [0;6]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # first layer: input\n",
    "        self.conv1 = nn.Conv2d(2, 8, 2)\n",
    "\n",
    "        #second layer : 2nd convolution\n",
    "        self.conv2 = nn.Conv2d(8, 16, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 32, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 16)\n",
    "\n",
    "        self.out = nn.Linear(16, 6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = self.out(x)\n",
    "    \n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(2, 8, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (out): Linear(in_features=16, out_features=6, bias=True)\n",
      ")\n",
      "number of parameters: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating model\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "print(f\"number of parameters: {len(params)}\")\n",
    "\n",
    "#loss function\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "dataloader = data.DataLoader(trainDataset, BATCH_SIZE)\n",
    "validationLoader = data.DataLoader(valDataset, BATCH_SIZE)\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        lossVal = loss(outputs, labels)\n",
    "        lossVal.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += lossVal.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(dataloader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "  batch 1000 loss: 1.5848046754598617\n",
      "  batch 2000 loss: 1.5772080620527267\n",
      "  batch 3000 loss: 1.5715919814109802\n",
      "  batch 4000 loss: 1.570342153787613\n",
      "  batch 5000 loss: 1.472266589641571\n",
      "  batch 6000 loss: 1.361961393892765\n",
      "  batch 7000 loss: 1.2709462715387345\n",
      "  batch 8000 loss: 0.9783029281198978\n",
      "  batch 9000 loss: 1.169719327032566\n",
      "  batch 10000 loss: 1.15325086414814\n",
      "Loss train 1.15325086414814 validation 1.1036205291748047\n",
      "EPOCH 2\n",
      "  batch 1000 loss: 1.1210624485611915\n",
      "  batch 2000 loss: 1.0930512836575508\n",
      "  batch 3000 loss: 1.0643902769088744\n",
      "  batch 4000 loss: 1.063572628557682\n",
      "  batch 5000 loss: 1.0348783017992973\n",
      "  batch 6000 loss: 1.0234251257181168\n",
      "  batch 7000 loss: 1.002744925737381\n",
      "  batch 8000 loss: 0.7666354396194219\n",
      "  batch 9000 loss: 0.9100256303399801\n",
      "  batch 10000 loss: 0.8938006875514984\n",
      "Loss train 0.8938006875514984 validation 0.9398242235183716\n",
      "EPOCH 3\n",
      "  batch 1000 loss: 0.9666195095181466\n",
      "  batch 2000 loss: 0.943132805198431\n",
      "  batch 3000 loss: 0.932166943192482\n",
      "  batch 4000 loss: 0.9401529870927334\n",
      "  batch 5000 loss: 0.9203544070422649\n",
      "  batch 6000 loss: 0.9047875367105007\n",
      "  batch 7000 loss: 0.8976959220170975\n",
      "  batch 8000 loss: 0.6870635501146316\n",
      "  batch 9000 loss: 0.7588882497251034\n",
      "  batch 10000 loss: 0.736291059076786\n",
      "Loss train 0.736291059076786 validation 0.8422553539276123\n",
      "EPOCH 4\n",
      "  batch 1000 loss: 0.8867198038101196\n",
      "  batch 2000 loss: 0.8542912537157535\n",
      "  batch 3000 loss: 0.838361478626728\n",
      "  batch 4000 loss: 0.8444905425310135\n",
      "  batch 5000 loss: 0.8367392613887786\n",
      "  batch 6000 loss: 0.8248691573441028\n",
      "  batch 7000 loss: 0.8191811257004737\n",
      "  batch 8000 loss: 0.6201407213434577\n",
      "  batch 9000 loss: 0.6670920702889561\n",
      "  batch 10000 loss: 0.6365541193187236\n",
      "Loss train 0.6365541193187236 validation 0.8447287678718567\n",
      "EPOCH 5\n",
      "  batch 1000 loss: 0.83141602024436\n",
      "  batch 2000 loss: 0.8044891560375691\n",
      "  batch 3000 loss: 0.8017503882050514\n",
      "  batch 4000 loss: 0.7959251726269722\n",
      "  batch 5000 loss: 0.793781172990799\n",
      "  batch 6000 loss: 0.7823648951351643\n",
      "  batch 7000 loss: 0.7753837157934904\n",
      "  batch 8000 loss: 0.5764211186021566\n",
      "  batch 9000 loss: 0.6027089493498207\n",
      "  batch 10000 loss: 0.5862770196050405\n",
      "Loss train 0.5862770196050405 validation 0.7882387638092041\n",
      "EPOCH 6\n",
      "  batch 1000 loss: 0.7947659642994404\n",
      "  batch 2000 loss: 0.771097106218338\n",
      "  batch 3000 loss: 0.7571441144049168\n",
      "  batch 4000 loss: 0.7604697745591402\n",
      "  batch 5000 loss: 0.7558834720999003\n",
      "  batch 6000 loss: 0.7418366447687149\n",
      "  batch 7000 loss: 0.7363420980125666\n",
      "  batch 8000 loss: 0.531639567002654\n",
      "  batch 9000 loss: 0.5615303472429514\n",
      "  batch 10000 loss: 0.5350267981030047\n",
      "Loss train 0.5350267981030047 validation 0.7783156037330627\n",
      "EPOCH 7\n",
      "  batch 1000 loss: 0.7679008899331092\n",
      "  batch 2000 loss: 0.7350112796127796\n",
      "  batch 3000 loss: 0.7279067615866661\n",
      "  batch 4000 loss: 0.7294397350698709\n",
      "  batch 5000 loss: 0.7159464571177959\n",
      "  batch 6000 loss: 0.7155964643061161\n",
      "  batch 7000 loss: 0.7069873354732991\n",
      "  batch 8000 loss: 0.506773322109133\n",
      "  batch 9000 loss: 0.5138858001567423\n",
      "  batch 10000 loss: 0.5023692549094558\n",
      "Loss train 0.5023692549094558 validation 0.7227255702018738\n",
      "EPOCH 8\n",
      "  batch 1000 loss: 0.7494382465183735\n",
      "  batch 2000 loss: 0.7056468580514192\n",
      "  batch 3000 loss: 0.7044480049163103\n",
      "  batch 4000 loss: 0.7023514380455017\n",
      "  batch 5000 loss: 0.6889430927634239\n",
      "  batch 6000 loss: 0.6934668641984463\n",
      "  batch 7000 loss: 0.6707313002124429\n",
      "  batch 8000 loss: 0.4761698370538652\n",
      "  batch 9000 loss: 0.47923319636657835\n",
      "  batch 10000 loss: 0.46533741598576306\n",
      "Loss train 0.46533741598576306 validation 0.698108434677124\n",
      "EPOCH 9\n",
      "  batch 1000 loss: 0.7254463104754686\n",
      "  batch 2000 loss: 0.68845637370646\n",
      "  batch 3000 loss: 0.6776876084804535\n",
      "  batch 4000 loss: 0.6864021070599556\n",
      "  batch 5000 loss: 0.6660325974225998\n",
      "  batch 6000 loss: 0.672372713342309\n",
      "  batch 7000 loss: 0.6589401698559523\n",
      "  batch 8000 loss: 0.45212441105023027\n",
      "  batch 9000 loss: 0.4619118278995156\n",
      "  batch 10000 loss: 0.4335351582467556\n",
      "Loss train 0.4335351582467556 validation 0.6563202738761902\n",
      "EPOCH 10\n",
      "  batch 1000 loss: 0.7046389763206243\n",
      "  batch 2000 loss: 0.6702945037782192\n",
      "  batch 3000 loss: 0.6615028134286404\n",
      "  batch 4000 loss: 0.6583534435778856\n",
      "  batch 5000 loss: 0.6610807644426823\n",
      "  batch 6000 loss: 0.6527225747853518\n",
      "  batch 7000 loss: 0.6478557813540101\n",
      "  batch 8000 loss: 0.43125885124318303\n",
      "  batch 9000 loss: 0.432843007452786\n",
      "  batch 10000 loss: 0.4208894909694791\n",
      "Loss train 0.4208894909694791 validation 0.6390317678451538\n",
      "EPOCH 11\n",
      "  batch 1000 loss: 0.682734268695116\n",
      "  batch 2000 loss: 0.6614417805969716\n",
      "  batch 3000 loss: 0.6499329867810011\n",
      "  batch 4000 loss: 0.6422392347157001\n",
      "  batch 5000 loss: 0.6356414394676685\n",
      "  batch 6000 loss: 0.64194346781075\n",
      "  batch 7000 loss: 0.6294929992258549\n",
      "  batch 8000 loss: 0.4186709449198097\n",
      "  batch 9000 loss: 0.4237182648796588\n",
      "  batch 10000 loss: 0.4082521043680608\n",
      "Loss train 0.4082521043680608 validation 0.6176177859306335\n",
      "EPOCH 12\n",
      "  batch 1000 loss: 0.6872143642604351\n",
      "  batch 2000 loss: 0.6573526435941458\n",
      "  batch 3000 loss: 0.6356478052586317\n",
      "  batch 4000 loss: 0.6268183221518994\n",
      "  batch 5000 loss: 0.6244157951176167\n",
      "  batch 6000 loss: 0.634989134401083\n",
      "  batch 7000 loss: 0.6258083952516318\n",
      "  batch 8000 loss: 0.39994210229627786\n",
      "  batch 9000 loss: 0.40444297915510835\n",
      "  batch 10000 loss: 0.4005714733786881\n",
      "Loss train 0.4005714733786881 validation 0.611839771270752\n",
      "EPOCH 13\n",
      "  batch 1000 loss: 0.6699195929765701\n",
      "  batch 2000 loss: 0.6327724977433682\n",
      "  batch 3000 loss: 0.6330101857483387\n",
      "  batch 4000 loss: 0.6181697361767292\n",
      "  batch 5000 loss: 0.608877857297659\n",
      "  batch 6000 loss: 0.6235277875959874\n",
      "  batch 7000 loss: 0.6148639786168932\n",
      "  batch 8000 loss: 0.39434234702028337\n",
      "  batch 9000 loss: 0.3853021551892161\n",
      "  batch 10000 loss: 0.38773934199661014\n",
      "Loss train 0.38773934199661014 validation 0.6038804650306702\n",
      "EPOCH 14\n",
      "  batch 1000 loss: 0.6533131606727839\n",
      "  batch 2000 loss: 0.617745683953166\n",
      "  batch 3000 loss: 0.6298281653523445\n",
      "  batch 4000 loss: 0.6063167158961296\n",
      "  batch 5000 loss: 0.598906685769558\n",
      "  batch 6000 loss: 0.6139930442422629\n",
      "  batch 7000 loss: 0.5987186649218201\n",
      "  batch 8000 loss: 0.37427560377772895\n",
      "  batch 9000 loss: 0.37452496081218123\n",
      "  batch 10000 loss: 0.39385036879219115\n",
      "Loss train 0.39385036879219115 validation 0.588007926940918\n",
      "EPOCH 15\n",
      "  batch 1000 loss: 0.6371824314668775\n",
      "  batch 2000 loss: 0.6074377992153168\n",
      "  batch 3000 loss: 0.6061624436527491\n",
      "  batch 4000 loss: 0.5943748523071408\n",
      "  batch 5000 loss: 0.5908321985453368\n",
      "  batch 6000 loss: 0.5995710975974798\n",
      "  batch 7000 loss: 0.5921617800816894\n",
      "  batch 8000 loss: 0.36339820172078907\n",
      "  batch 9000 loss: 0.37626211550459265\n",
      "  batch 10000 loss: 0.3657472871728241\n",
      "Loss train 0.3657472871728241 validation 0.5800681710243225\n",
      "EPOCH 16\n",
      "  batch 1000 loss: 0.6318387076482177\n",
      "  batch 2000 loss: 0.5939548528045416\n",
      "  batch 3000 loss: 0.596889304175973\n",
      "  batch 4000 loss: 0.5883691572546959\n",
      "  batch 5000 loss: 0.5813523345366121\n",
      "  batch 6000 loss: 0.6038870230317116\n",
      "  batch 7000 loss: 0.5734757657945156\n",
      "  batch 8000 loss: 0.3544666825048626\n",
      "  batch 9000 loss: 0.35929238827899096\n",
      "  batch 10000 loss: 0.3566026320457458\n",
      "Loss train 0.3566026320457458 validation 0.585335373878479\n",
      "EPOCH 17\n",
      "  batch 1000 loss: 0.626651862770319\n",
      "  batch 2000 loss: 0.5817846498191357\n",
      "  batch 3000 loss: 0.5852808546870947\n",
      "  batch 4000 loss: 0.5724683390408755\n",
      "  batch 5000 loss: 0.5759867084845901\n",
      "  batch 6000 loss: 0.5836609973907471\n",
      "  batch 7000 loss: 0.5668464862927795\n",
      "  batch 8000 loss: 0.34491028706356885\n",
      "  batch 9000 loss: 0.34674230801686645\n",
      "  batch 10000 loss: 0.3603722093394026\n",
      "Loss train 0.3603722093394026 validation 0.5582578182220459\n",
      "EPOCH 18\n",
      "  batch 1000 loss: 0.6180783730372786\n",
      "  batch 2000 loss: 0.5697758455127477\n",
      "  batch 3000 loss: 0.5785850515887141\n",
      "  batch 4000 loss: 0.5740112640336156\n",
      "  batch 5000 loss: 0.5567379411309957\n",
      "  batch 6000 loss: 0.5706410413831472\n",
      "  batch 7000 loss: 0.5636598347201943\n",
      "  batch 8000 loss: 0.3388310892963782\n",
      "  batch 9000 loss: 0.33997725232318043\n",
      "  batch 10000 loss: 0.34173691944312307\n",
      "Loss train 0.34173691944312307 validation 0.5667731165885925\n",
      "EPOCH 19\n",
      "  batch 1000 loss: 0.6056515919268132\n",
      "  batch 2000 loss: 0.5684202916622162\n",
      "  batch 3000 loss: 0.5725924377441406\n",
      "  batch 4000 loss: 0.5646463255882264\n",
      "  batch 5000 loss: 0.5594606110304594\n",
      "  batch 6000 loss: 0.5680521754920482\n",
      "  batch 7000 loss: 0.5551865320950746\n",
      "  batch 8000 loss: 0.3295054679615423\n",
      "  batch 9000 loss: 0.3345037630777806\n",
      "  batch 10000 loss: 0.3421134553104639\n",
      "Loss train 0.3421134553104639 validation 0.5554923415184021\n",
      "EPOCH 20\n",
      "  batch 1000 loss: 0.5935746854022145\n",
      "  batch 2000 loss: 0.5632749598026275\n",
      "  batch 3000 loss: 0.5632396476715803\n",
      "  batch 4000 loss: 0.5923111943230033\n",
      "  batch 5000 loss: 0.5467019193023444\n",
      "  batch 6000 loss: 0.5586824364662171\n",
      "  batch 7000 loss: 0.5623804821670055\n",
      "  batch 8000 loss: 0.3229494813526981\n",
      "  batch 9000 loss: 0.3279202521760017\n",
      "  batch 10000 loss: 0.34377561761252584\n",
      "Loss train 0.34377561761252584 validation 0.5518881678581238\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n",
    "writer = SummaryWriter(\"runs/imitation_learning_{}\".format(timestamp))\n",
    "epoch_num = 0\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "EPOCHS = 14\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH {}\".format(epoch_num + 1))\n",
    "\n",
    "    net.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_num, writer)\n",
    "\n",
    "    net.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(validationLoader):\n",
    "        vinputs, vlabels = vdata\n",
    "        vout = net(vinputs)\n",
    "        vloss = loss(vout, vlabels)\n",
    "        running_vloss += vloss\n",
    "    avg_vloss = running_vloss / (i+1)\n",
    "    print(f\"Loss train {avg_loss} validation {avg_vloss}\")\n",
    "\n",
    "\n",
    "    writer.add_scalars(\"Training Loss\", {\"Training\" : avg_loss, \"validation\" : avg_vloss})\n",
    "    writer.flush()\n",
    "\n",
    "    epoch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['>' '.' '.' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.01\n",
      "[[['.' '>' '.' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.015\n",
      "[[['.' '.' '>' 'O']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: move, reward: 0.017499999999999998\n",
      "[[['.' '.' '.' 'r']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n",
      "action: turnLeft, reward: 0.017499999999999998\n",
      "[[['.' '.' '.' 'u']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]\n",
      "\n",
      " [['.' '.' '.' '^']\n",
      "  ['#' '#' '.' '#']\n",
      "  ['.' '#' '.' '#']\n",
      "  ['.' '#' '#' '#']]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.045, 5, False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "actions = [\"move\", \"turnRight\", \"turnLeft\", \"pickMarker\", \"putMarker\", \"finish\"]\n",
    "\n",
    "testMDP = MDP(dir = \"data\", type = \"val\", name = \"100112\")\n",
    "\n",
    "def apply_to_grid(MDP, show_grid):\n",
    "    reward = 0\n",
    "    steps = 0\n",
    "    if show_grid:\n",
    "        MDP.print_grid()\n",
    "    while True:\n",
    "        current_grid = torch.tensor(MDP.get_current_state(), device= device) / 10\n",
    "        out = net(current_grid.unsqueeze(0))\n",
    "        nextAction = actions[torch.argmax(out)]\n",
    "        reward += MDP.gamma**steps * MDP.reward(nextAction)\n",
    "        steps += 1\n",
    "        if MDP.get_next_state(nextAction) == \"Terminal\" or steps > 100:\n",
    "            return reward, steps, MDP.task_solved()\n",
    "        if show_grid:\n",
    "            print(\"action: {}, reward: {}\".format(nextAction, reward))\n",
    "            MDP.print_grid()\n",
    "\n",
    "\n",
    "apply_to_grid(testMDP, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks solved with only imitation learning:\n",
      "Total : 2475, accuracy: 0.1436448055716773\n"
     ]
    }
   ],
   "source": [
    "# check accuracy of solved tasks\n",
    "sucesses = 0\n",
    "for dir in [\"data\", \"data_easy\", \"data_medium\"]:\n",
    "    for type in [\"val\"]:\n",
    "        for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "            i = re.sub(r\"\\D\", \"\", i)\n",
    "            curr_MDP = MDP(dir, type, i)\n",
    "            if apply_to_grid(curr_MDP, False)[-1]:\n",
    "                sucesses += 1\n",
    "\n",
    "print(\"tasks solved with only imitation learning:\")\n",
    "print(f\"Total : {sucesses}, accuracy: {sucesses / len(valDataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clearly seen here, imitation learning with the limited amount of training data is not able to solve most of the provided tasks. Therefore, in the following I will use the described PPO approach and after that will create the final model that uses imitation learning to initiate the model and then trains it with maskless PPO to achieve the best possible performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['.' '#' '.' '.']\n",
      "  ['#' '.' '.' '.']\n",
      "  ['O' '#' '.' '#']\n",
      "  ['v' '.' '#' '#']]\n",
      "\n",
      " [['.' '#' '.' '.']\n",
      "  ['#' '.' '.' '.']\n",
      "  ['>' '#' '.' '#']\n",
      "  ['.' '.' '#' '#']]]\n"
     ]
    }
   ],
   "source": [
    "# test generated MDPs\n",
    "test = np.random.randint(1, 1e5)\n",
    "\n",
    "genMDP = MDP(\"generated\", \"train\", str(test))\n",
    "\n",
    "genMDP.print_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom environment\n",
    "from gym import spaces\n",
    "\n",
    "class Gridworld(gym.Env):\n",
    "\n",
    "    metadata = {\"render.modes\" : [\"human\"]}\n",
    "\n",
    "    def MDP_generator(self):\n",
    "        for dir in self.dir:\n",
    "            for type in self.type:\n",
    "                for i in os.listdir(os.sep.join([\"datasets\", dir, type, \"task\"]))[:-4]:\n",
    "                    i = re.sub(r\"\\D\", \"\", i)\n",
    "                    yield dir, type, i\n",
    "\n",
    "    def __init__(self, dir = [\"data\", \"data_easy\", \"data_medium\"], type = [\"train\"]) -> None:\n",
    "        super(Gridworld, self).__init__()\n",
    "        self.action_space = spaces.Discrete(7)\n",
    "        self.observation_space = spaces.Discrete(low = 0, high = 10, shape = (4, 4, 2))\n",
    "\n",
    "        #available MDPs\n",
    "        self.dir = dir\n",
    "        self.type = type\n",
    "\n",
    "        self.next_MDP = self.MDP_generator()\n",
    "        self.actions = [\"move\", \"turnLeft\", \"turnRight\", \"pickMarker\", \"putMarker\", \"finish\"]\n",
    "\n",
    "    def reset(self):\n",
    "        nextDir, nextType, nexti =  next(self.next_MDP)\n",
    "        self.currentMDP = MDP(nextDir, nextType, nexti)\n",
    "        return self.currentMDP.get_current_state() / 10\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.currentMDP.sample_next_state_and_reward(self.actions[action])\n",
    "        \n",
    "    def render(self):\n",
    "        self.currentMDP.print_grid()\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
